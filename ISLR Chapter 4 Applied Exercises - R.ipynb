{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 1\n",
    "\n",
    "**This question should be answered using the `Weekly` data set, which is part of the `ISLR` package. This data is similar in nature to the `Smarket` data from this chapter's lab, except that it contains 1,089 weekly returns for 21 years, from the beginning of 1990 to the end of 2010.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th><th scope=col>Direction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1990     </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>-0.229   </td><td>-3.484   </td><td>0.1549760</td><td>-0.270   </td><td>Down     </td></tr>\n",
       "\t<tr><td>1990     </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>-0.229   </td><td>0.1485740</td><td>-2.576   </td><td>Down     </td></tr>\n",
       "\t<tr><td>1990     </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>0.1598375</td><td> 3.514   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>0.1616300</td><td> 0.712   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 0.712   </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td>0.1537280</td><td> 1.178   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 1.178   </td><td> 0.712   </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td>0.1544440</td><td>-1.372   </td><td>Down     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction\\\\\n",
       "\\hline\n",
       "\t 1990      &  0.816    &  1.572    & -3.936    & -0.229    & -3.484    & 0.1549760 & -0.270    & Down     \\\\\n",
       "\t 1990      & -0.270    &  0.816    &  1.572    & -3.936    & -0.229    & 0.1485740 & -2.576    & Down     \\\\\n",
       "\t 1990      & -2.576    & -0.270    &  0.816    &  1.572    & -3.936    & 0.1598375 &  3.514    & Up       \\\\\n",
       "\t 1990      &  3.514    & -2.576    & -0.270    &  0.816    &  1.572    & 0.1616300 &  0.712    & Up       \\\\\n",
       "\t 1990      &  0.712    &  3.514    & -2.576    & -0.270    &  0.816    & 0.1537280 &  1.178    & Up       \\\\\n",
       "\t 1990      &  1.178    &  0.712    &  3.514    & -2.576    & -0.270    & 0.1544440 & -1.372    & Down     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Year | Lag1 | Lag2 | Lag3 | Lag4 | Lag5 | Volume | Today | Direction |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1990      |  0.816    |  1.572    | -3.936    | -0.229    | -3.484    | 0.1549760 | -0.270    | Down      |\n",
       "| 1990      | -0.270    |  0.816    |  1.572    | -3.936    | -0.229    | 0.1485740 | -2.576    | Down      |\n",
       "| 1990      | -2.576    | -0.270    |  0.816    |  1.572    | -3.936    | 0.1598375 |  3.514    | Up        |\n",
       "| 1990      |  3.514    | -2.576    | -0.270    |  0.816    |  1.572    | 0.1616300 |  0.712    | Up        |\n",
       "| 1990      |  0.712    |  3.514    | -2.576    | -0.270    |  0.816    | 0.1537280 |  1.178    | Up        |\n",
       "| 1990      |  1.178    |  0.712    |  3.514    | -2.576    | -0.270    | 0.1544440 | -1.372    | Down      |\n",
       "\n"
      ],
      "text/plain": [
       "  Year Lag1   Lag2   Lag3   Lag4   Lag5   Volume    Today  Direction\n",
       "1 1990  0.816  1.572 -3.936 -0.229 -3.484 0.1549760 -0.270 Down     \n",
       "2 1990 -0.270  0.816  1.572 -3.936 -0.229 0.1485740 -2.576 Down     \n",
       "3 1990 -2.576 -0.270  0.816  1.572 -3.936 0.1598375  3.514 Up       \n",
       "4 1990  3.514 -2.576 -0.270  0.816  1.572 0.1616300  0.712 Up       \n",
       "5 1990  0.712  3.514 -2.576 -0.270  0.816 0.1537280  1.178 Up       \n",
       "6 1990  1.178  0.712  3.514 -2.576 -0.270 0.1544440 -1.372 Down     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "**Produce some numerical and graphical summaries of the `Weekly` data. Do there appear to be any patterns?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Year           Lag1               Lag2               Lag3         \n",
       " Min.   :1990   Min.   :-18.1950   Min.   :-18.1950   Min.   :-18.1950  \n",
       " 1st Qu.:1995   1st Qu.: -1.1540   1st Qu.: -1.1540   1st Qu.: -1.1580  \n",
       " Median :2000   Median :  0.2410   Median :  0.2410   Median :  0.2410  \n",
       " Mean   :2000   Mean   :  0.1506   Mean   :  0.1511   Mean   :  0.1472  \n",
       " 3rd Qu.:2005   3rd Qu.:  1.4050   3rd Qu.:  1.4090   3rd Qu.:  1.4090  \n",
       " Max.   :2010   Max.   : 12.0260   Max.   : 12.0260   Max.   : 12.0260  \n",
       "      Lag4               Lag5              Volume            Today         \n",
       " Min.   :-18.1950   Min.   :-18.1950   Min.   :0.08747   Min.   :-18.1950  \n",
       " 1st Qu.: -1.1580   1st Qu.: -1.1660   1st Qu.:0.33202   1st Qu.: -1.1540  \n",
       " Median :  0.2380   Median :  0.2340   Median :1.00268   Median :  0.2410  \n",
       " Mean   :  0.1458   Mean   :  0.1399   Mean   :1.57462   Mean   :  0.1499  \n",
       " 3rd Qu.:  1.4090   3rd Qu.:  1.4050   3rd Qu.:2.05373   3rd Qu.:  1.4050  \n",
       " Max.   : 12.0260   Max.   : 12.0260   Max.   :9.32821   Max.   : 12.0260  \n",
       " Direction \n",
       " Down:484  \n",
       " Up  :605  \n",
       "           \n",
       "           \n",
       "           \n",
       "           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(Weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAABlBMVEUAAAD///+l2Z/dAAAA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\n6QAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs(Weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the initial summary statistics and scatterplot matrix, there don't appear to be any obvious patterns aside from the fact the volume of shares traded each week has grown quite a lot from 1990 to 2010. Looking more closely at the scatterplot of just volume over time, we can see that the number of shares traded each week has grown exponentially over the 21 years covered by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(Weekly$Volume, ylab = \"Shares traded (in billions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Year</th><td> 1.00000000 </td><td>-0.032289274</td><td>-0.03339001 </td><td>-0.03000649 </td><td>-0.031127923</td><td>-0.030519101</td><td> 0.84194162 </td><td>-0.032459894</td></tr>\n",
       "\t<tr><th scope=row>Lag1</th><td>-0.03228927 </td><td> 1.000000000</td><td>-0.07485305 </td><td> 0.05863568 </td><td>-0.071273876</td><td>-0.008183096</td><td>-0.06495131 </td><td>-0.075031842</td></tr>\n",
       "\t<tr><th scope=row>Lag2</th><td>-0.03339001 </td><td>-0.074853051</td><td> 1.00000000 </td><td>-0.07572091 </td><td> 0.058381535</td><td>-0.072499482</td><td>-0.08551314 </td><td> 0.059166717</td></tr>\n",
       "\t<tr><th scope=row>Lag3</th><td>-0.03000649 </td><td> 0.058635682</td><td>-0.07572091 </td><td> 1.00000000 </td><td>-0.075395865</td><td> 0.060657175</td><td>-0.06928771 </td><td>-0.071243639</td></tr>\n",
       "\t<tr><th scope=row>Lag4</th><td>-0.03112792 </td><td>-0.071273876</td><td> 0.05838153 </td><td>-0.07539587 </td><td> 1.000000000</td><td>-0.075675027</td><td>-0.06107462 </td><td>-0.007825873</td></tr>\n",
       "\t<tr><th scope=row>Lag5</th><td>-0.03051910 </td><td>-0.008183096</td><td>-0.07249948 </td><td> 0.06065717 </td><td>-0.075675027</td><td> 1.000000000</td><td>-0.05851741 </td><td> 0.011012698</td></tr>\n",
       "\t<tr><th scope=row>Volume</th><td> 0.84194162 </td><td>-0.064951313</td><td>-0.08551314 </td><td>-0.06928771 </td><td>-0.061074617</td><td>-0.058517414</td><td> 1.00000000 </td><td>-0.033077783</td></tr>\n",
       "\t<tr><th scope=row>Today</th><td>-0.03245989 </td><td>-0.075031842</td><td> 0.05916672 </td><td>-0.07124364 </td><td>-0.007825873</td><td> 0.011012698</td><td>-0.03307778 </td><td> 1.000000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today\\\\\n",
       "\\hline\n",
       "\tYear &  1.00000000  & -0.032289274 & -0.03339001  & -0.03000649  & -0.031127923 & -0.030519101 &  0.84194162  & -0.032459894\\\\\n",
       "\tLag1 & -0.03228927  &  1.000000000 & -0.07485305  &  0.05863568  & -0.071273876 & -0.008183096 & -0.06495131  & -0.075031842\\\\\n",
       "\tLag2 & -0.03339001  & -0.074853051 &  1.00000000  & -0.07572091  &  0.058381535 & -0.072499482 & -0.08551314  &  0.059166717\\\\\n",
       "\tLag3 & -0.03000649  &  0.058635682 & -0.07572091  &  1.00000000  & -0.075395865 &  0.060657175 & -0.06928771  & -0.071243639\\\\\n",
       "\tLag4 & -0.03112792  & -0.071273876 &  0.05838153  & -0.07539587  &  1.000000000 & -0.075675027 & -0.06107462  & -0.007825873\\\\\n",
       "\tLag5 & -0.03051910  & -0.008183096 & -0.07249948  &  0.06065717  & -0.075675027 &  1.000000000 & -0.05851741  &  0.011012698\\\\\n",
       "\tVolume &  0.84194162  & -0.064951313 & -0.08551314  & -0.06928771  & -0.061074617 & -0.058517414 &  1.00000000  & -0.033077783\\\\\n",
       "\tToday & -0.03245989  & -0.075031842 &  0.05916672  & -0.07124364  & -0.007825873 &  0.011012698 & -0.03307778  &  1.000000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Year | Lag1 | Lag2 | Lag3 | Lag4 | Lag5 | Volume | Today |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Year |  1.00000000  | -0.032289274 | -0.03339001  | -0.03000649  | -0.031127923 | -0.030519101 |  0.84194162  | -0.032459894 |\n",
       "| Lag1 | -0.03228927  |  1.000000000 | -0.07485305  |  0.05863568  | -0.071273876 | -0.008183096 | -0.06495131  | -0.075031842 |\n",
       "| Lag2 | -0.03339001  | -0.074853051 |  1.00000000  | -0.07572091  |  0.058381535 | -0.072499482 | -0.08551314  |  0.059166717 |\n",
       "| Lag3 | -0.03000649  |  0.058635682 | -0.07572091  |  1.00000000  | -0.075395865 |  0.060657175 | -0.06928771  | -0.071243639 |\n",
       "| Lag4 | -0.03112792  | -0.071273876 |  0.05838153  | -0.07539587  |  1.000000000 | -0.075675027 | -0.06107462  | -0.007825873 |\n",
       "| Lag5 | -0.03051910  | -0.008183096 | -0.07249948  |  0.06065717  | -0.075675027 |  1.000000000 | -0.05851741  |  0.011012698 |\n",
       "| Volume |  0.84194162  | -0.064951313 | -0.08551314  | -0.06928771  | -0.061074617 | -0.058517414 |  1.00000000  | -0.033077783 |\n",
       "| Today | -0.03245989  | -0.075031842 |  0.05916672  | -0.07124364  | -0.007825873 |  0.011012698 | -0.03307778  |  1.000000000 |\n",
       "\n"
      ],
      "text/plain": [
       "       Year        Lag1         Lag2        Lag3        Lag4        \n",
       "Year    1.00000000 -0.032289274 -0.03339001 -0.03000649 -0.031127923\n",
       "Lag1   -0.03228927  1.000000000 -0.07485305  0.05863568 -0.071273876\n",
       "Lag2   -0.03339001 -0.074853051  1.00000000 -0.07572091  0.058381535\n",
       "Lag3   -0.03000649  0.058635682 -0.07572091  1.00000000 -0.075395865\n",
       "Lag4   -0.03112792 -0.071273876  0.05838153 -0.07539587  1.000000000\n",
       "Lag5   -0.03051910 -0.008183096 -0.07249948  0.06065717 -0.075675027\n",
       "Volume  0.84194162 -0.064951313 -0.08551314 -0.06928771 -0.061074617\n",
       "Today  -0.03245989 -0.075031842  0.05916672 -0.07124364 -0.007825873\n",
       "       Lag5         Volume      Today       \n",
       "Year   -0.030519101  0.84194162 -0.032459894\n",
       "Lag1   -0.008183096 -0.06495131 -0.075031842\n",
       "Lag2   -0.072499482 -0.08551314  0.059166717\n",
       "Lag3    0.060657175 -0.06928771 -0.071243639\n",
       "Lag4   -0.075675027 -0.06107462 -0.007825873\n",
       "Lag5    1.000000000 -0.05851741  0.011012698\n",
       "Volume -0.058517414  1.00000000 -0.033077783\n",
       "Today   0.011012698 -0.03307778  1.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor(Weekly[-9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we look at the matrix of correlations between the variables. Looking at the last row, we can see that each of the lag variables is only correlated very weakly with today's returns. The sole substantial value of 0.842, between `Volume` and `Year`, aligns with the strong correlation we saw in the above scatterplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "**Use the full data set to perform a logistic regression with `Direction` as the response and the five lag variables plus `Volume` as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ . - Year - Today, family = \"binomial\", \n",
       "    data = Weekly)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.6949  -1.2565   0.9913   1.0849   1.4579  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)   \n",
       "(Intercept)  0.26686    0.08593   3.106   0.0019 **\n",
       "Lag1        -0.04127    0.02641  -1.563   0.1181   \n",
       "Lag2         0.05844    0.02686   2.175   0.0296 * \n",
       "Lag3        -0.01606    0.02666  -0.602   0.5469   \n",
       "Lag4        -0.02779    0.02646  -1.050   0.2937   \n",
       "Lag5        -0.01447    0.02638  -0.549   0.5833   \n",
       "Volume      -0.02274    0.03690  -0.616   0.5377   \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1496.2  on 1088  degrees of freedom\n",
       "Residual deviance: 1486.4  on 1082  degrees of freedom\n",
       "AIC: 1500.4\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.full = glm(Direction ~ . - Year - Today, data = Weekly, family = \"binomial\")\n",
    "summary(glm.full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only statistically significant predictor is `Lag2`, with a p-value of 0.0296 providing evidence at the 5% significance level to reject the null hypothesis that it is not related to the response `Direction`. None of the other predictors are statistically significant, though `Lag1` is somewhat near the border of being significant at the 10% level, with a p-value of 0.1181."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "**Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             \n",
       "glm.full.pred Down  Up\n",
       "         Down   54  48\n",
       "         Up    430 557"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.full.probs = predict(glm.full, type = \"response\")\n",
    "glm.full.pred = rep(\"Down\", 1089)\n",
    "glm.full.pred[glm.full.probs > 0.5] = \"Up\"\n",
    "table(glm.full.pred, Weekly$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.561065197428834"
      ],
      "text/latex": [
       "0.561065197428834"
      ],
      "text/markdown": [
       "0.561065197428834"
      ],
      "text/plain": [
       "[1] 0.5610652"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(glm.full.pred == Weekly$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the confusion matrix, the logistic regression model using the five lag variables along with `Volume` as the predictors, and a prediction threshold of 0.5, correctly predicted 54 down weeks out of a total of 484 actual down weeks and 557 up days out of a total of 605 actual up weeks. This means that the model correctly predicted the direction for 611 weeks out of the 1089 for an accuracy of 0.5612. While this seems to be better than random chance, it is important to note that the model was trained on the entire data set, so 0.5612 is the *training* accuracy. Moreover, a naive strategy of simply saying that every week will be an up week would have resulted in 605 correctly predicted weeks out of 1089, which is a very similar level of overall accuracy.\n",
    "\n",
    "To look a little closer at the confusion matrix, let's assume that our goal is to correctly predict when the market will go up. In this case, up weeks will be considered as positive ($+$) and down weeks as negative ($-$). Having set this convention, we can now consider four important quantities associated with the confusion matrix: true positive rate (i.e. *sensitivity* or *recall*), false positive rate, positive predictive value (i.e. *precision*), and negative predictive value. The true positive rate is the number of correctly predicted positives divided by the overall number of positives -- the number of correctly predicted up weeks (557) over the total number of up weeks (605) for a value of $557/605 \\approx 0.92$ for this model. While this is a pretty high value, which is good, the false positive rate -- the number of incorrectly predicted positives (weeks incorrectly predicted to be up weeks = 430 weeks) divided by the overall number of negatives (the total number of down weeks = 484 weeks) -- is comparably high at $430/484 \\approx 0.888$, which might be quite bad depending on our sensitivity to losing money on an incorrectly predicted down week. Next is the positive predictive value, which is the number of true positives divided by the total number of predicted positives; in our case this is $557/987 \\approx 0.564$. This is better than chance, but as already noted we would have a comparable positive predictive value if we just predicted that every week would be an up week. Lastly is the negative predictive value, which is the number of true negatives divided by the total number of predicted negatives; in our case this is $54/102 \\approx 0.529$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "**Now fit the logistic regression model using a training data period from 1990 to 2008, with `Lag2` as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from 2009 and 2010).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (Weekly$Year < 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag2, family = \"binomial\", data = Weekly, \n",
       "    subset = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "   Min      1Q  Median      3Q     Max  \n",
       "-1.536  -1.264   1.021   1.091   1.368  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)   \n",
       "(Intercept)  0.20326    0.06428   3.162  0.00157 **\n",
       "Lag2         0.05810    0.02870   2.024  0.04298 * \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1354.7  on 984  degrees of freedom\n",
       "Residual deviance: 1350.5  on 983  degrees of freedom\n",
       "AIC: 1354.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(Direction ~ Lag2, data = Weekly, subset = train, family = \"binomial\")\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "glm.pred Down Up\n",
       "    Down    9  5\n",
       "    Up     34 56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.probs = predict(glm.fit, Weekly[!train, ], type = \"response\")\n",
    "glm.pred = rep(\"Down\", dim(Weekly[!train, ])[1])\n",
    "glm.pred[glm.probs > 0.5] = \"Up\"\n",
    "table(glm.pred, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.625"
      ],
      "text/latex": [
       "0.625"
      ],
      "text/markdown": [
       "0.625"
      ],
      "text/plain": [
       "[1] 0.625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(glm.pred == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.586538461538462"
      ],
      "text/latex": [
       "0.586538461538462"
      ],
      "text/markdown": [
       "0.586538461538462"
      ],
      "text/plain": [
       "[1] 0.5865385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(Weekly[!train, ]$Direction == \"Up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting a logistic regression model on the data from 1990 through 2008 using only `Lag2` as the predictor, the model correctly predicted the market direction for 62.5% of the weeks in the held-out data (the data from 2009 and 2010). While this is better than chance, it still is less than a 10% improvement over naively predicting that every week will be an up week. Continuing with the convention from Part 3 that an up week is a positive result, the true positive rate is $56/61 \\approx 0.918$, while the false positive rate is $34/43 \\approx 0.791$. In addition, the positive predictive value is $56/90 \\approx 0.622$ and the negative predictive value is $9/14 \\approx 0.643$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "**Repeat Part 4 using LDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call:\n",
       "lda(Direction ~ Lag2, data = Weekly, subset = train)\n",
       "\n",
       "Prior probabilities of groups:\n",
       "     Down        Up \n",
       "0.4477157 0.5522843 \n",
       "\n",
       "Group means:\n",
       "            Lag2\n",
       "Down -0.03568254\n",
       "Up    0.26036581\n",
       "\n",
       "Coefficients of linear discriminants:\n",
       "           LD1\n",
       "Lag2 0.4414162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      \n",
       "       Down Up\n",
       "  Down    9  5\n",
       "  Up     34 56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda.pred = predict(lda.fit, Weekly[!train, ])\n",
    "table(lda.pred$class, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.625"
      ],
      "text/latex": [
       "0.625"
      ],
      "text/markdown": [
       "0.625"
      ],
      "text/plain": [
       "[1] 0.625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(lda.pred$class == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing linear discriminant analysis on the data from 1990 through 2008 using only `Lag2` as the predictor, we ended up with an identical confusion matrix to the one from Part 4 with the logistic regression model. As we saw in Part 4, the model correctly predicted the market direction for 62.5% of the weeks in the held-out data (the data from 2009 and 2010). While this is better than chance, it still is less than a 10% improvement over naively predicting that every week will be an up week. Continuing with the convention from Part 3 that an up week is a positive result, the true positive rate is $56/61 \\approx 0.918$, while the false positive rate is $34/43 \\approx 0.791$. In addition, the positive predictive value is $56/90 \\approx 0.622$ and the negative predictive value is $9/14 \\approx 0.643$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6\n",
    "**Repeat Part 4 using QDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call:\n",
       "qda(Direction ~ Lag2, data = Weekly, subset = train)\n",
       "\n",
       "Prior probabilities of groups:\n",
       "     Down        Up \n",
       "0.4477157 0.5522843 \n",
       "\n",
       "Group means:\n",
       "            Lag2\n",
       "Down -0.03568254\n",
       "Up    0.26036581"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.fit = qda(Direction ~ Lag2, data = Weekly, subset = train)\n",
    "qda.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      \n",
       "       Down Up\n",
       "  Down    0  0\n",
       "  Up     43 61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.pred = predict(qda.fit, Weekly[!train, ])\n",
    "table(qda.pred$class, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.586538461538462"
      ],
      "text/latex": [
       "0.586538461538462"
      ],
      "text/markdown": [
       "0.586538461538462"
      ],
      "text/plain": [
       "[1] 0.5865385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(qda.pred$class == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing quadratic discriminant analysis on the data from 1990 through 2008 using only `Lag2` as the predictor, we ended up with a model that ended up predicting that every week in 2009 and 2010 would be an up week. The model correctly predicted the market direction for 58.7% of the weeks in the held-out data (the data from 2009 and 2010). While this is better than chance, it is the same result one would get from naively predicting that every week will be an up week, so to better compare the performance of this model to the logistic regression and linear discriminant analysis models testing on a larger test set would be necessary. Continuing with the convention from Part 3 that an up week is a positive result, the true positive rate is $61/61 = 1$, while the false positive rate is $43/43 \\approx 1$. In addition, the positive predictive value is $61/104 \\approx 0.587$ and since there were no negative predictions discussing the negative predictive value is meaningless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7\n",
    "**Repeat Part 4 using KNN with $K = 1$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.X = data.frame(Weekly[train, ]$Lag2)\n",
    "test.X = data.frame(Weekly[!train, ]$Lag2)\n",
    "train.Direction = Weekly[train, ]$Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "knn.pred Down Up\n",
       "    Down   21 30\n",
       "    Up     22 31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "knn.pred = knn(train.X, test.X, train.Direction, k = 1)\n",
    "table(knn.pred, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.5"
      ],
      "text/latex": [
       "0.5"
      ],
      "text/markdown": [
       "0.5"
      ],
      "text/plain": [
       "[1] 0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(knn.pred == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing $k$-nearest neighbors classification with $k = 1$ on the data from 1990 through 2008 using only `Lag2` as the predictor, the model correctly predicted the market direction for 50% of the weeks in the held-out data (the data from 2009 and 2010). While this only as good as picking the direction randomly, it had worse performance than naively predicting that every week will be an up week. Continuing with the convention from Part 3 that an up week is a positive result, the true positive rate is $31/61 \\approx 0.508$, while the false positive rate is $22/43 \\approx 0.512$. In addition, the positive predictive value is $31/53 \\approx 0.585$ and the negative predictive value is $21/51 \\approx 0.412$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8\n",
    "**Which of these methods appears to provide the best results on this data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are only considering overall prediction accuracy, it appears that logistic regression and linear discriminant analysis were equally good as the models that performed the best on this data. Quadratic discriminant analysis came in third place, and $k$-nearest neighbors with $k = 1$ a distant fourth. As noted above in Part 7, $k$-nearest neighbors didn't perform any better than randomly guessing, and in fact performed worse than naively predicting every week would be an up week. One thing that I would be cautious of, though, is the fact that aside from KNN, the other three models very strongly preferred to predict up weeks, and therefore had high false positive rates. This might be okay for an investor who is comfortable with taking more risks and has can afford losing money to down weeks that were incorrectly predicted to be up weeks, but a risk-averse investor would probably want to use a less aggressive model, or at least require a higher probability threshold than 50% before accepting a prediction of an up week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9\n",
    "**Experiment with different combinations of predictors, including possible transformations and interactions, for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data. Note that you should also experiment with values for $K$ in the KNN classifier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of predictors I will try out is a weighted average of the lag variables where the recent lag values are weighted more heavily than the ones further in the past. More specifically, I will try out giving `Lag1` a weight of 40%, `Lag2` a weight of 35%, `Lag3` a weight of 15%, and `Lag4` and `Lag5` each weights of 5%. Note that I don't have a strong reason for these particular values of the weights aside from the intuitive assumption that recent weeks might be more-related to the direction of the current week than weeks that are further in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th><th scope=col>Direction</th><th scope=col>weighted.lag.avg</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1990     </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>-0.229   </td><td>-3.484   </td><td>0.1549760</td><td>-0.270   </td><td>Down     </td><td> 0.10055 </td></tr>\n",
       "\t<tr><td>1990     </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>-0.229   </td><td>0.1485740</td><td>-2.576   </td><td>Down     </td><td> 0.20515 </td></tr>\n",
       "\t<tr><td>1990     </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>0.1598375</td><td> 3.514   </td><td>Up       </td><td>-1.12070 </td></tr>\n",
       "\t<tr><td>1990     </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>0.1616300</td><td> 0.712   </td><td>Up       </td><td> 0.58290 </td></tr>\n",
       "\t<tr><td>1990     </td><td> 0.712   </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td>0.1537280</td><td> 1.178   </td><td>Up       </td><td> 1.15560 </td></tr>\n",
       "\t<tr><td>1990     </td><td> 1.178   </td><td> 0.712   </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td>0.1544440</td><td>-1.372   </td><td>Down     </td><td> 1.10520 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction & weighted.lag.avg\\\\\n",
       "\\hline\n",
       "\t 1990      &  0.816    &  1.572    & -3.936    & -0.229    & -3.484    & 0.1549760 & -0.270    & Down      &  0.10055 \\\\\n",
       "\t 1990      & -0.270    &  0.816    &  1.572    & -3.936    & -0.229    & 0.1485740 & -2.576    & Down      &  0.20515 \\\\\n",
       "\t 1990      & -2.576    & -0.270    &  0.816    &  1.572    & -3.936    & 0.1598375 &  3.514    & Up        & -1.12070 \\\\\n",
       "\t 1990      &  3.514    & -2.576    & -0.270    &  0.816    &  1.572    & 0.1616300 &  0.712    & Up        &  0.58290 \\\\\n",
       "\t 1990      &  0.712    &  3.514    & -2.576    & -0.270    &  0.816    & 0.1537280 &  1.178    & Up        &  1.15560 \\\\\n",
       "\t 1990      &  1.178    &  0.712    &  3.514    & -2.576    & -0.270    & 0.1544440 & -1.372    & Down      &  1.10520 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Year | Lag1 | Lag2 | Lag3 | Lag4 | Lag5 | Volume | Today | Direction | weighted.lag.avg |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1990      |  0.816    |  1.572    | -3.936    | -0.229    | -3.484    | 0.1549760 | -0.270    | Down      |  0.10055  |\n",
       "| 1990      | -0.270    |  0.816    |  1.572    | -3.936    | -0.229    | 0.1485740 | -2.576    | Down      |  0.20515  |\n",
       "| 1990      | -2.576    | -0.270    |  0.816    |  1.572    | -3.936    | 0.1598375 |  3.514    | Up        | -1.12070  |\n",
       "| 1990      |  3.514    | -2.576    | -0.270    |  0.816    |  1.572    | 0.1616300 |  0.712    | Up        |  0.58290  |\n",
       "| 1990      |  0.712    |  3.514    | -2.576    | -0.270    |  0.816    | 0.1537280 |  1.178    | Up        |  1.15560  |\n",
       "| 1990      |  1.178    |  0.712    |  3.514    | -2.576    | -0.270    | 0.1544440 | -1.372    | Down      |  1.10520  |\n",
       "\n"
      ],
      "text/plain": [
       "  Year Lag1   Lag2   Lag3   Lag4   Lag5   Volume    Today  Direction\n",
       "1 1990  0.816  1.572 -3.936 -0.229 -3.484 0.1549760 -0.270 Down     \n",
       "2 1990 -0.270  0.816  1.572 -3.936 -0.229 0.1485740 -2.576 Down     \n",
       "3 1990 -2.576 -0.270  0.816  1.572 -3.936 0.1598375  3.514 Up       \n",
       "4 1990  3.514 -2.576 -0.270  0.816  1.572 0.1616300  0.712 Up       \n",
       "5 1990  0.712  3.514 -2.576 -0.270  0.816 0.1537280  1.178 Up       \n",
       "6 1990  1.178  0.712  3.514 -2.576 -0.270 0.1544440 -1.372 Down     \n",
       "  weighted.lag.avg\n",
       "1  0.10055        \n",
       "2  0.20515        \n",
       "3 -1.12070        \n",
       "4  0.58290        \n",
       "5  1.15560        \n",
       "6  1.10520        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted.lag.avg = 0.4*Weekly$Lag1 + 0.35*Weekly$Lag2 + 0.15*Weekly$Lag3 + 0.05*Weekly$Lag4 + 0.05*Weekly$Lag5\n",
    "Weekly = data.frame(Weekly, weighted.lag.avg)\n",
    "head(Weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-0.0372414071307195"
      ],
      "text/latex": [
       "-0.0372414071307195"
      ],
      "text/markdown": [
       "-0.0372414071307195"
      ],
      "text/plain": [
       "[1] -0.03724141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor(Weekly$Today, Weekly$weighted.lag.avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the correlation between this weighted average and the value of the current week's return, we see that there only a very weak correlation between the two quantities. It is smaller in magnitude than the correlations between `Today` and the first the lag variables individually. That seems to suggest that this weighting might not be too useful, but I will still try out each of the classification methods using this transformation of the predictors. I will start out with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ weighted.lag.avg, family = \"binomial\", \n",
       "    data = Weekly, subset = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "   Min      1Q  Median      3Q     Max  \n",
       "-1.345  -1.264   1.074   1.092   1.127  \n",
       "\n",
       "Coefficients:\n",
       "                 Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)       0.21349    0.06446   3.312 0.000926 ***\n",
       "weighted.lag.avg -0.02816    0.05347  -0.527 0.598508    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1354.7  on 984  degrees of freedom\n",
       "Residual deviance: 1354.4  on 983  degrees of freedom\n",
       "AIC: 1358.4\n",
       "\n",
       "Number of Fisher Scoring iterations: 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(Direction ~ weighted.lag.avg, data = Weekly, subset = train, family = \"binomial\")\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "glm.pred Down Up\n",
       "      Up   43 61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.probs = predict(glm.fit, Weekly[!train, ], type = \"response\")\n",
    "glm.pred = rep(\"Down\", dim(Weekly[!train, ])[1])\n",
    "glm.pred[glm.probs > 0.5] = \"Up\"\n",
    "table(glm.pred, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.586538461538462"
      ],
      "text/latex": [
       "0.586538461538462"
      ],
      "text/markdown": [
       "0.586538461538462"
      ],
      "text/plain": [
       "[1] 0.5865385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(glm.pred == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results with logistic regression aren't particularly encouraing, as with a prediction threshold of 50% this method was equivalent to always predicting that the market would go up when evaluated on the test set. In addition, the p-value for the coefficient of `weighted.lag.avg` is 0.598, which means that there isn't evidence to say that it is statistically significant. Thinking a little more about the idea of using a weighted average, it makes sense that the performance with logistic regression won't provide an improvement over what we did in Part 4, since the weighted average is still a linear combination of the variables. We already saw that in a logistic regression model, `Lag2` was the only statistically significant coefficient, and even then it is borderline at the 5% significance level, so the weighted average includes variables which we already had reason to believe weren't particularly helpful in making a strong model. I'll still try out the remaining methods with `weighted.lag.avg` before trying out one other combination of the predictors. Next up is linear discriminant analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit = lda(Direction ~ weighted.lag.avg, data = Weekly, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      \n",
       "       Down Up\n",
       "  Down    0  0\n",
       "  Up     43 61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda.pred = predict(lda.fit, Weekly[!train, ])\n",
    "table(lda.pred$class, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.586538461538462"
      ],
      "text/latex": [
       "0.586538461538462"
      ],
      "text/markdown": [
       "0.586538461538462"
      ],
      "text/plain": [
       "[1] 0.5865385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(lda.pred$class == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear discriminant analysis has the same performance as logistic regression. This is reasonable since the two methods often perform similarly. Now we'll consider quadratic discriminant analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.fit = qda(Direction ~ weighted.lag.avg, data = Weekly, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      \n",
       "       Down Up\n",
       "  Down    0  0\n",
       "  Up     43 61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.pred = predict(qda.fit, Weekly[!train, ])\n",
    "table(qda.pred$class, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.586538461538462"
      ],
      "text/latex": [
       "0.586538461538462"
      ],
      "text/markdown": [
       "0.586538461538462"
      ],
      "text/plain": [
       "[1] 0.5865385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(qda.pred$class == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.943525706180473"
      ],
      "text/latex": [
       "0.943525706180473"
      ],
      "text/markdown": [
       "0.943525706180473"
      ],
      "text/plain": [
       "[1] 0.9435257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max(qda.pred$posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic discriminant analysis also performed the same, but when checking the maximum value in the dataframe of posterior probabilities, I noticed that the maximum probability from QDA is 0.943. This means that it could be meaningful to try out a stricter threshold for predicting an up week. I will try out a threshold of 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          \n",
       "qda.pred60 Down Up\n",
       "      Down   37 48\n",
       "      Up      6 13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.pred60 = rep(\"Down\", dim(Weekly[!train, ])[1])\n",
    "qda.pred60[qda.pred$posterior[, \"Up\"] > 0.6] = \"Up\"\n",
    "table(qda.pred60, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.480769230769231"
      ],
      "text/latex": [
       "0.480769230769231"
      ],
      "text/markdown": [
       "0.480769230769231"
      ],
      "text/plain": [
       "[1] 0.4807692"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(qda.pred60 == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a somewhat stricter probability threshold of 60% for predicting an up week, we see that our overall prediction accuracy goes down to 48.1%. However, our false positive rate is now $6/43 \\approx 0.14$, which is a big improvement over the false positive rate of 1 from Part 6. In addition, our positive predictive value is $13/19 \\approx 0.684$, which is also an improvement over the value of 0.587 from Part 6. This suggests that if we are risk-averse investors who only want to invest our money when there is a pretty good chance of the market going up, then QDA with our weighted average of the lag variables and a stricter probability threshold could be promising.  Last up is $k$-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.X = data.frame(Weekly[train, \"weighted.lag.avg\"])\n",
    "test.X = data.frame(Weekly[!train, \"weighted.lag.avg\"])\n",
    "train.Direction = Weekly[train, \"Direction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "knn.pred Down Up\n",
       "    Down   14 28\n",
       "    Up     29 33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "knn.pred = knn(train.X, test.X, train.Direction, k = 1)\n",
    "table(knn.pred, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.451923076923077"
      ],
      "text/latex": [
       "0.451923076923077"
      ],
      "text/markdown": [
       "0.451923076923077"
      ],
      "text/plain": [
       "[1] 0.4519231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(knn.pred == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $k = 1$, KNN performs even worse than random guessing when it comes to overall prediction accuracy, and the true positive rate (0.541), false positive rate (0.674), and positive predictive rate (0.532) aren't encouraging when compared to the result from Part 8. Before moving on, let's try out two more values for $k$: $k = 3$ and $k = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "knn.pred Down Up\n",
       "    Down   15 28\n",
       "    Up     28 33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "knn.pred = knn(train.X, test.X, train.Direction, k = 3)\n",
    "table(knn.pred, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.461538461538462"
      ],
      "text/latex": [
       "0.461538461538462"
      ],
      "text/markdown": [
       "0.461538461538462"
      ],
      "text/plain": [
       "[1] 0.4615385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(knn.pred == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "knn.pred Down Up\n",
       "    Down   13 26\n",
       "    Up     30 35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "knn.pred = knn(train.X, test.X, train.Direction, k = 5)\n",
    "table(knn.pred, Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.461538461538462"
      ],
      "text/latex": [
       "0.461538461538462"
      ],
      "text/markdown": [
       "0.461538461538462"
      ],
      "text/plain": [
       "[1] 0.4615385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(knn.pred == Weekly[!train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when we increase the value of $k$, the results are largely the same. While it would be best to compare these different models using additional tools, such as computing ROC curves and AUC scores for each model, I'll save that for Chapter 9 when we discuss how to produce them in R more in depth. For now, it looks like as far as using `weighted.lag.avg` to make predictions goes, the most-promising model is QDA with a prediction threshold of 60%. \n",
    "\n",
    "If I have time to revisit this exercise in the future, I think it would be intersting to try out a different weighting strategy, where each lag variable is weighted based on the number of shares during the corresponding week of trading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 2\n",
    "\n",
    "**In this problem, you will develop a model to predict whether a given car gets high or low gas mileage based on the `Auto` data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>mpg</th><th scope=col>cylinders</th><th scope=col>displacement</th><th scope=col>horsepower</th><th scope=col>weight</th><th scope=col>acceleration</th><th scope=col>year</th><th scope=col>origin</th><th scope=col>name</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>18                       </td><td>8                        </td><td>307                      </td><td>130                      </td><td>3504                     </td><td>12.0                     </td><td>70                       </td><td>1                        </td><td>chevrolet chevelle malibu</td></tr>\n",
       "\t<tr><td>15                       </td><td>8                        </td><td>350                      </td><td>165                      </td><td>3693                     </td><td>11.5                     </td><td>70                       </td><td>1                        </td><td>buick skylark 320        </td></tr>\n",
       "\t<tr><td>18                       </td><td>8                        </td><td>318                      </td><td>150                      </td><td>3436                     </td><td>11.0                     </td><td>70                       </td><td>1                        </td><td>plymouth satellite       </td></tr>\n",
       "\t<tr><td>16                       </td><td>8                        </td><td>304                      </td><td>150                      </td><td>3433                     </td><td>12.0                     </td><td>70                       </td><td>1                        </td><td>amc rebel sst            </td></tr>\n",
       "\t<tr><td>17                       </td><td>8                        </td><td>302                      </td><td>140                      </td><td>3449                     </td><td>10.5                     </td><td>70                       </td><td>1                        </td><td>ford torino              </td></tr>\n",
       "\t<tr><td>15                       </td><td>8                        </td><td>429                      </td><td>198                      </td><td>4341                     </td><td>10.0                     </td><td>70                       </td><td>1                        </td><td>ford galaxie 500         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " mpg & cylinders & displacement & horsepower & weight & acceleration & year & origin & name\\\\\n",
       "\\hline\n",
       "\t 18                        & 8                         & 307                       & 130                       & 3504                      & 12.0                      & 70                        & 1                         & chevrolet chevelle malibu\\\\\n",
       "\t 15                        & 8                         & 350                       & 165                       & 3693                      & 11.5                      & 70                        & 1                         & buick skylark 320        \\\\\n",
       "\t 18                        & 8                         & 318                       & 150                       & 3436                      & 11.0                      & 70                        & 1                         & plymouth satellite       \\\\\n",
       "\t 16                        & 8                         & 304                       & 150                       & 3433                      & 12.0                      & 70                        & 1                         & amc rebel sst            \\\\\n",
       "\t 17                        & 8                         & 302                       & 140                       & 3449                      & 10.5                      & 70                        & 1                         & ford torino              \\\\\n",
       "\t 15                        & 8                         & 429                       & 198                       & 4341                      & 10.0                      & 70                        & 1                         & ford galaxie 500         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| mpg | cylinders | displacement | horsepower | weight | acceleration | year | origin | name |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 18                        | 8                         | 307                       | 130                       | 3504                      | 12.0                      | 70                        | 1                         | chevrolet chevelle malibu |\n",
       "| 15                        | 8                         | 350                       | 165                       | 3693                      | 11.5                      | 70                        | 1                         | buick skylark 320         |\n",
       "| 18                        | 8                         | 318                       | 150                       | 3436                      | 11.0                      | 70                        | 1                         | plymouth satellite        |\n",
       "| 16                        | 8                         | 304                       | 150                       | 3433                      | 12.0                      | 70                        | 1                         | amc rebel sst             |\n",
       "| 17                        | 8                         | 302                       | 140                       | 3449                      | 10.5                      | 70                        | 1                         | ford torino               |\n",
       "| 15                        | 8                         | 429                       | 198                       | 4341                      | 10.0                      | 70                        | 1                         | ford galaxie 500          |\n",
       "\n"
      ],
      "text/plain": [
       "  mpg cylinders displacement horsepower weight acceleration year origin\n",
       "1 18  8         307          130        3504   12.0         70   1     \n",
       "2 15  8         350          165        3693   11.5         70   1     \n",
       "3 18  8         318          150        3436   11.0         70   1     \n",
       "4 16  8         304          150        3433   12.0         70   1     \n",
       "5 17  8         302          140        3449   10.5         70   1     \n",
       "6 15  8         429          198        4341   10.0         70   1     \n",
       "  name                     \n",
       "1 chevrolet chevelle malibu\n",
       "2 buick skylark 320        \n",
       "3 plymouth satellite       \n",
       "4 amc rebel sst            \n",
       "5 ford torino              \n",
       "6 ford galaxie 500         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Auto = read.csv(\"Auto.csv\", header = TRUE, na.strings = \"?\")\n",
    "Auto = na.omit(Auto)\n",
    "head(Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `origin` column actually contains categorical data, even though it is coded using integers. In order to make my life a little easier for performing regression, I'm going replace the values in that column with their meanings and convert it to a factor column. There are also [other options for coding categorical variables](https://stats.idre.ucla.edu/r/modules/coding-for-categorical-variables-in-regression-models/), such as using the `factor()` function directly within `lm()`, or using the `C()` function to have more control over the contrast coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>mpg</th><th scope=col>cylinders</th><th scope=col>displacement</th><th scope=col>horsepower</th><th scope=col>weight</th><th scope=col>acceleration</th><th scope=col>year</th><th scope=col>origin</th><th scope=col>name</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>18                       </td><td>8                        </td><td>307                      </td><td>130                      </td><td>3504                     </td><td>12.0                     </td><td>70                       </td><td>American                 </td><td>chevrolet chevelle malibu</td></tr>\n",
       "\t<tr><td>15                       </td><td>8                        </td><td>350                      </td><td>165                      </td><td>3693                     </td><td>11.5                     </td><td>70                       </td><td>American                 </td><td>buick skylark 320        </td></tr>\n",
       "\t<tr><td>18                       </td><td>8                        </td><td>318                      </td><td>150                      </td><td>3436                     </td><td>11.0                     </td><td>70                       </td><td>American                 </td><td>plymouth satellite       </td></tr>\n",
       "\t<tr><td>16                       </td><td>8                        </td><td>304                      </td><td>150                      </td><td>3433                     </td><td>12.0                     </td><td>70                       </td><td>American                 </td><td>amc rebel sst            </td></tr>\n",
       "\t<tr><td>17                       </td><td>8                        </td><td>302                      </td><td>140                      </td><td>3449                     </td><td>10.5                     </td><td>70                       </td><td>American                 </td><td>ford torino              </td></tr>\n",
       "\t<tr><td>15                       </td><td>8                        </td><td>429                      </td><td>198                      </td><td>4341                     </td><td>10.0                     </td><td>70                       </td><td>American                 </td><td>ford galaxie 500         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " mpg & cylinders & displacement & horsepower & weight & acceleration & year & origin & name\\\\\n",
       "\\hline\n",
       "\t 18                        & 8                         & 307                       & 130                       & 3504                      & 12.0                      & 70                        & American                  & chevrolet chevelle malibu\\\\\n",
       "\t 15                        & 8                         & 350                       & 165                       & 3693                      & 11.5                      & 70                        & American                  & buick skylark 320        \\\\\n",
       "\t 18                        & 8                         & 318                       & 150                       & 3436                      & 11.0                      & 70                        & American                  & plymouth satellite       \\\\\n",
       "\t 16                        & 8                         & 304                       & 150                       & 3433                      & 12.0                      & 70                        & American                  & amc rebel sst            \\\\\n",
       "\t 17                        & 8                         & 302                       & 140                       & 3449                      & 10.5                      & 70                        & American                  & ford torino              \\\\\n",
       "\t 15                        & 8                         & 429                       & 198                       & 4341                      & 10.0                      & 70                        & American                  & ford galaxie 500         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| mpg | cylinders | displacement | horsepower | weight | acceleration | year | origin | name |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 18                        | 8                         | 307                       | 130                       | 3504                      | 12.0                      | 70                        | American                  | chevrolet chevelle malibu |\n",
       "| 15                        | 8                         | 350                       | 165                       | 3693                      | 11.5                      | 70                        | American                  | buick skylark 320         |\n",
       "| 18                        | 8                         | 318                       | 150                       | 3436                      | 11.0                      | 70                        | American                  | plymouth satellite        |\n",
       "| 16                        | 8                         | 304                       | 150                       | 3433                      | 12.0                      | 70                        | American                  | amc rebel sst             |\n",
       "| 17                        | 8                         | 302                       | 140                       | 3449                      | 10.5                      | 70                        | American                  | ford torino               |\n",
       "| 15                        | 8                         | 429                       | 198                       | 4341                      | 10.0                      | 70                        | American                  | ford galaxie 500          |\n",
       "\n"
      ],
      "text/plain": [
       "  mpg cylinders displacement horsepower weight acceleration year origin  \n",
       "1 18  8         307          130        3504   12.0         70   American\n",
       "2 15  8         350          165        3693   11.5         70   American\n",
       "3 18  8         318          150        3436   11.0         70   American\n",
       "4 16  8         304          150        3433   12.0         70   American\n",
       "5 17  8         302          140        3449   10.5         70   American\n",
       "6 15  8         429          198        4341   10.0         70   American\n",
       "  name                     \n",
       "1 chevrolet chevelle malibu\n",
       "2 buick skylark 320        \n",
       "3 plymouth satellite       \n",
       "4 amc rebel sst            \n",
       "5 ford torino              \n",
       "6 ford galaxie 500         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Auto$origin[Auto$origin == 1] = \"American\"\n",
    "Auto$origin[Auto$origin == 2] = \"European\"\n",
    "Auto$origin[Auto$origin == 3] = \"Japanese\"\n",
    "Auto$origin = as.factor(Auto$origin)\n",
    "head(Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "**Create a binary variable, `mpg01`, that contains a 1 if `mpg` contains a value above its median, and a 0 if `mpg` contains a value below its median. You can compute the median using the `median()` function. Note you may find it helpful to use the `data.frame()` function to create a single data set containing both `mpg01` and the other `Auto` variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>mpg</th><th scope=col>cylinders</th><th scope=col>displacement</th><th scope=col>horsepower</th><th scope=col>weight</th><th scope=col>acceleration</th><th scope=col>year</th><th scope=col>origin</th><th scope=col>name</th><th scope=col>mpg01</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>18                       </td><td>8                        </td><td>307                      </td><td>130                      </td><td>3504                     </td><td>12.0                     </td><td>70                       </td><td>American                 </td><td>chevrolet chevelle malibu</td><td>0                        </td></tr>\n",
       "\t<tr><td>15                       </td><td>8                        </td><td>350                      </td><td>165                      </td><td>3693                     </td><td>11.5                     </td><td>70                       </td><td>American                 </td><td>buick skylark 320        </td><td>0                        </td></tr>\n",
       "\t<tr><td>18                       </td><td>8                        </td><td>318                      </td><td>150                      </td><td>3436                     </td><td>11.0                     </td><td>70                       </td><td>American                 </td><td>plymouth satellite       </td><td>0                        </td></tr>\n",
       "\t<tr><td>16                       </td><td>8                        </td><td>304                      </td><td>150                      </td><td>3433                     </td><td>12.0                     </td><td>70                       </td><td>American                 </td><td>amc rebel sst            </td><td>0                        </td></tr>\n",
       "\t<tr><td>17                       </td><td>8                        </td><td>302                      </td><td>140                      </td><td>3449                     </td><td>10.5                     </td><td>70                       </td><td>American                 </td><td>ford torino              </td><td>0                        </td></tr>\n",
       "\t<tr><td>15                       </td><td>8                        </td><td>429                      </td><td>198                      </td><td>4341                     </td><td>10.0                     </td><td>70                       </td><td>American                 </td><td>ford galaxie 500         </td><td>0                        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " mpg & cylinders & displacement & horsepower & weight & acceleration & year & origin & name & mpg01\\\\\n",
       "\\hline\n",
       "\t 18                        & 8                         & 307                       & 130                       & 3504                      & 12.0                      & 70                        & American                  & chevrolet chevelle malibu & 0                        \\\\\n",
       "\t 15                        & 8                         & 350                       & 165                       & 3693                      & 11.5                      & 70                        & American                  & buick skylark 320         & 0                        \\\\\n",
       "\t 18                        & 8                         & 318                       & 150                       & 3436                      & 11.0                      & 70                        & American                  & plymouth satellite        & 0                        \\\\\n",
       "\t 16                        & 8                         & 304                       & 150                       & 3433                      & 12.0                      & 70                        & American                  & amc rebel sst             & 0                        \\\\\n",
       "\t 17                        & 8                         & 302                       & 140                       & 3449                      & 10.5                      & 70                        & American                  & ford torino               & 0                        \\\\\n",
       "\t 15                        & 8                         & 429                       & 198                       & 4341                      & 10.0                      & 70                        & American                  & ford galaxie 500          & 0                        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| mpg | cylinders | displacement | horsepower | weight | acceleration | year | origin | name | mpg01 |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 18                        | 8                         | 307                       | 130                       | 3504                      | 12.0                      | 70                        | American                  | chevrolet chevelle malibu | 0                         |\n",
       "| 15                        | 8                         | 350                       | 165                       | 3693                      | 11.5                      | 70                        | American                  | buick skylark 320         | 0                         |\n",
       "| 18                        | 8                         | 318                       | 150                       | 3436                      | 11.0                      | 70                        | American                  | plymouth satellite        | 0                         |\n",
       "| 16                        | 8                         | 304                       | 150                       | 3433                      | 12.0                      | 70                        | American                  | amc rebel sst             | 0                         |\n",
       "| 17                        | 8                         | 302                       | 140                       | 3449                      | 10.5                      | 70                        | American                  | ford torino               | 0                         |\n",
       "| 15                        | 8                         | 429                       | 198                       | 4341                      | 10.0                      | 70                        | American                  | ford galaxie 500          | 0                         |\n",
       "\n"
      ],
      "text/plain": [
       "  mpg cylinders displacement horsepower weight acceleration year origin  \n",
       "1 18  8         307          130        3504   12.0         70   American\n",
       "2 15  8         350          165        3693   11.5         70   American\n",
       "3 18  8         318          150        3436   11.0         70   American\n",
       "4 16  8         304          150        3433   12.0         70   American\n",
       "5 17  8         302          140        3449   10.5         70   American\n",
       "6 15  8         429          198        4341   10.0         70   American\n",
       "  name                      mpg01\n",
       "1 chevrolet chevelle malibu 0    \n",
       "2 buick skylark 320         0    \n",
       "3 plymouth satellite        0    \n",
       "4 amc rebel sst             0    \n",
       "5 ford torino               0    \n",
       "6 ford galaxie 500          0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpg01 = rep(0, dim(Auto)[1])\n",
    "mpg01[Auto$mpg > median(Auto$mpg)] = 1\n",
    "Auto = data.frame(Auto, mpg01)\n",
    "head(Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "**Explore the data graphically in order to investigate the association between `mpg01` and the other features. Which of the other features seem most likely to be useful in predicting `mpg01`? Scatterplots and boxplots may be useful tools to answer this question. Describe your findings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\n",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "par(mfrow = c(2, 3))\n",
    "plot(factor(Auto$mpg01), Auto$cylinders, ylab = \"Number of engine cylinders\")\n",
    "plot(factor(Auto$mpg01), Auto$displacement, ylab = \"Engine displacement (cubic inches)\")\n",
    "plot(factor(Auto$mpg01), Auto$horsepower, ylab = \"Horsepower\")\n",
    "plot(factor(Auto$mpg01), Auto$weight, ylab = \"Weight (pounds)\")\n",
    "plot(factor(Auto$mpg01), Auto$acceleration, ylab = \"Time to reach 60mpg (seconds)\")\n",
    "plot(factor(Auto$mpg01), Auto$year, ylab = \"Manufacture year\")\n",
    "mtext(\"Boxplots for cars with above(1) and below(0) median mpg\", outer = TRUE, line = -3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I made boxplots to compare the overall distributions for each of the quantitative variables between cars with above-median mpg and those with below median-mpg. Starting in the upper-left corner, we see that aside from some outliers, the the majority of cars with above-median mpg have four-cylinder engines. Moving to the upper-middle pair of boxplots, at least 75% of the cars with above-median mpg have smaller engines than 75% of the cars with below-median mpg. This is also true for horsepower (upper-right pair of boxplots) and weight (lower-left pair of boxplots). We also see in the final two pairs of boxplots, for acceleration and manufacture year, that while there are definitely differences between cars with above-median mpg and those with below-median mpg, the differences aren't as strong compared to the first four predictors. In particular, there is a lot more overlap in both time to reach 60mpg and manufacture year between the two categories of cars, whereas for the other predictors there is almost no overlap for the boxplots between the two categories. This suggests that `cylinders`, `displacement`, `horsepower`, and `weight` will be the most useful in predicting `mpg01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nRiwAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "par(mfrow = c(3, 2))\n",
    "plot(Auto$cylinders, Auto$mpg01, xlab = \"Number of engine cylinders\")\n",
    "plot(Auto$displacement, Auto$mpg01, xlab = \"Engine displacement (cubic inches)\")\n",
    "plot(Auto$horsepower, Auto$mpg01, xlab = \"Horsepower\")\n",
    "plot(Auto$weight, Auto$mpg01, xlab = \"Weight (pounds)\")\n",
    "plot(Auto$acceleration, Auto$mpg01, xlab = \"Time to reach 60mpg (seconds)\")\n",
    "plot(Auto$year, Auto$mpg01, xlab = \"Manufacture year\")\n",
    "mtext(\"Scatterplots for cars with above(1) and below(0) median mpg\", outer = TRUE, line = -3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at scatterplots with `mpg01` on the y-axis and the various quantitative variables on the x-axes provides further evidence to suggest that `horsepower` and `weight` will be useful in predicting `mpg01`, with decently clear clusterings of above-median mpgs at the low ends and clusterings of below-median mpgs at the high ends of the ranges of each variable. The scatterplots involving `cylinders` and `discplacement` seem to indicate that those variables wouldn't be as helpful on their own, at least for logistic regression. The small number of possibilities for the number of engine cylinders (3, 4, 5, 6, or 8) results in overlap in the scatterplot, because each engine cylinder configuration has at least one car in each category. For engine displacement, the overlap mainly comes from a decent number of cars with below-median mpg and engine displacements in the bottom 25%. For now I'll still include them with the other variables in the following parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD/AAD///89ODILAAAACXBIWXMAABJ0\nAAASdAHeZh94AAAgAElEQVR4nO3dC3eqShKG4cZrYtTx///aEfBCPDsoRVV1dfM+a02SNfu0\nhcQv9E1MFwCzpdwHANSAIAEKCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoI\nEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCAB\nCggSoIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoIEqCA\nIAEKCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggS\noIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEK\nCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggSoIAg\nAQoIEqCAIAEKCBKggCABCggSoIAgAQoIEqDAIUgJKIzgVa4fnAwlAE0ECVBAkAAFBAlQQJAA\nBQQJUECQAAUECVBAkAAFBAlQQJAABQQJUECQAAUECVBAkAAFBAlQQJAABQQJUECQUDrR+7zV\nD8KlScASqESXovxRIkgoWxp8zYggoWjp5XsuBAlFI0iZS6AOBClzCVSCMVLeEqgEs3Z5S6Aa\nrCPlLAFoIkiAAoIEKCBIgAKCBCggSIACggQoIEiAAoIEKCBIgAKCBCggSIACggQoIEiAAoIE\nKCBIgAKCBCggSIACggQoIEiAAoIEKCBIKB13EcpZApXgvnZ5S6AS3Gk1bwnUgXt/Zy6BOhCk\nzCVQh3SbbMj9kiFIKBuTDXlLoBIEKW8J1IGuXeYSqIPrZMPI0i9BQtEcgzTaiSRIKJvfguxo\nJYKEsrlNNoxf+wgSSue0aZUgAQoIEqCBMRKggFk7QAXrSIAtgoTS8VbznCVQCTat5i2BSvBW\n87wlUAfeIZu5BGx5DVwIUuYSsOQ3cCFImUvAkuPAhTFS3hIw5HmZYNYubwkY8u1vsY6UswQM\nRRm4OCJIMBBk4OKIIMFAkIGLI4IEEyEGLo4IEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEK\nCBKggCABCggSoIAgAQoIEqCAIAEKCBKggCABCggSShfiPYQECWUL8q52goSyBbnPCkFC0aLc\n+YsgoWgEKXMJ1IEgZS6BSjBGylsClWDWLm8JVIN1pJwlAE0ECaXjipSzBCrBGClvCVSCWbu8\nJVAH1pEyl0AdCFLmEqjDIoP0s9+k1mb3Y1UCS7O8MdJ5lZ7WJiWwPMubtdul5vvY/XQ6NGln\nUQJLtLR1pCYdHz8fU2NRAsjEMUi//m6M/xEhSCgMVyRAge8Y6XDqfmKMhNp4Tn+vB7N2q7NJ\nCSAP33WkXbeO1Gz2rCOhLuxsABTECVIasikBWMkSpLdBIUgoDEECFLguyH7ceyNIKIxjkH4a\ngoRaeXbtzpu07lZk6dqhNr5jpO+Uvi8EaQmWNvXqPNlwWqfNmSBVL8ibhBy5z9rtU3MgSLUL\n8rZVR/7T38fV+6v+kn4DNYpyIwVHOdaRtgSpcgUESXsMF2eLkHMJGAofJP0xHEGCgehjpNRd\nkQgSggs+a5dux6d4gAQJJkKvI92OjSABcxiM4QgSlocrEqCAMRKggVk7QAHrSIAKdjYAAREk\nQAFBAhQQJEABQULpQuxGIkgoW5D9sQQJZfN8x8bItY8goWiO7yEcvfYRJBTNM0hjhQgSiuYX\npPFKBAllcxsjESTUTDhrN33OnCChboJ1JFH6GCMBv4n6g8zaAb9IZyhYRwIGuPkJoIAgoWpu\n20/158wJEqKQbj/1mrUbf0SXJgFLIBzZZcJtHenN47k0CVgC0QgHLp67v0cQJAQhC1K6XVwU\nZ7JFjQgSghAGSXTTVNnOBhZkUQL5doPJoZCVGmtEkBCF/DIxtZno4semVZRCNJEt6NoRJOA3\n0WQDQQJe6A93RI0IEsqmPwEnakSQUDrtJSFRI4KE0nGn1ZwlUAnutJq3BCrBXru8JVAH4VZX\ndQQJRSNImUvAltcMAEHKXAIfC/EO1L9LDb6a12L6G1L691LU5ZdZFmQxgyQTvv0t314kQYKE\nwf7OQrFpFTMQpDuChBlkmRCOkUJs9vkLQcIcsnccuG3JdsQYCTP43TcuyGafPzFrh1mcOlwF\nDKxYR0J8BQRpBEFCEARJX5nnEvNEHyONIkiIIvqs3SiChDhCryONI0hYJD7WBZiNDxoTPVq5\nHQZ8IMTab/1BKnoIi7ckv1+DmfYFBEn9ERFJkPdLVR+kspf58E6Ut3kQJBRN+jaPdmDFGEnw\nUASpTsIgMWsnfCxyVCvZ+6W4Ik1/LGbtiiFZqGDWzq0E60hlkP7Jm/77JUiomF8nPF0En5f5\n9iEdmgQsgWjEl4kQd4IlSAhCGKQg91khSAhC2N8S7myga4dapd7ERi/fP21EkFCrGbfrnxqk\nWymChPqk2yqpx5KQcIKQ23EhPulkg6CR7IrEDSJRAsdZO9kYaTSyBAlB3MLgcXdk6QzFSCOC\nhChkiztunyhIkFAG0fS3cPe3oBRBQinEtzERzDZIl6wYI6FGjtPfzNphFr+3oXhdkYQThKwj\nQc7vjZHCyYbB12lt2CIER8JNAG6VeIds3hL4jMFrTrsSd1rNWQKfKSBIklrq/VWChFF1Bkl/\nBoUgYVz0MVIQBKlQor+oXre7knG9cRpXJFykG8yEL9TQ60jSQhflzBKkIslW5iWN6sSdVtFy\nXc6XCX1XTt5qjk74IAW/T7T4rU8jD+nSJGCJosUPkluli+TKws4G9IKPkaJf/LgioRfk9qJ/\nVnr5bl9rapAYI6Hnto4k4RgkWSlm7VAE116k5IZAone1vzkOhyYBS8CS53YISS+NIKEQfpsU\nBl8nNKJrBwykJLi6MNkA/CYM0vCbznG4NAlYAnUQ3XqfBdkqVbi72o+olya9InEXocAqfb+P\nF2GQZFN9l7/PH0HKzXvjTuRzK7uNieiDJQSzdqPnjyBl5rcJwHPfjoh835Nssx33/q4JQXqQ\nXSaEM9naW8YJUmYE6U4YCf211T8L/f7+738VPKChqL9rC4yRboRTad572hkjBcWs3Y34ium1\nEZ5Zu+CiryM5vVANthuM15JEiXUkCLm9h9BgA9zftQZfNR/RuknAEviQ6DUnbOQ0bcAWIbgT\nveZkL1S/G1gSJHhzDJKsX8fnI+Utgc+4BknCr+v5wSNaNwlYAh8K8kIdr+TVi3x/HLZNApbA\nhyq98xefRiF4tLiLkJ0qj6/CO38tfB0p+Hp++OMTin3zE1mlZe9s8DvRMtGPT8TxrwN77XxK\nuF76BaIfn4zrXweni9/4b4ogZRb9+EQKeFK8H0n4UFF/p9GPTyT8k+IdstLHCvsrDX98EvGD\nNPiq02gBQQo+Kxb9+ERjkOB/HQxWcWcGKT2td9Mf6pMSCo8W+mUa/fiCL8iKGKzi6gUppeZd\ny5/9pvsPN7ufz0sgL+HFJfRfB4Ou59yu3bY5XL8emvRz2aTxa9J5Nbx+aR8VbIQf7ojodz1n\nBmmXjt334zUZ57QabbdLzXf/X5+uwRsNXV2/taJVGiT1rufsrt3ghzcH1txC1zqO9wPr+q0V\nrc4g6Xc9ZwapeVyRmrdBSv9MoNZRwUjwCbgoZnft7mOk3eX7zcCHK1KRgk/ARTF3smH9nDxI\n6Wu0XRu6U/eT8xgp9ARSAUK/jUJaKljX7noxame0N+1lKe3fNFwPZu1WZ+Wj+vux+Is6S/R1\nJOHxFf1hzD+7bh2p2ewd15Ho48+jv5tGl+z4os3aGTFYKCNJMqLz53jS00Xw+UgGN3WdHaTv\n9iKzPSgcydD8h3s87Mt3TBM+SJL7swbc2XAf92w+b//VpNX4tARXpDjiB2n47dNGL981jmNe\nk+f095totI6b1Hxd9s5bhBgjzRN8jCQLUriu3XNBdnx7UP/ftHZpe76cNuPBY9YujuCzdgaf\nqyw7jnlNfm0RemPbrh3t+pXYN/vyWEeyEfpjXWREkw3xpr+fm1bfD5L64779h2wR8hd9cUdY\navB1SrNgC7L7boz004yPefp2XcPvvk/HFiF/0Rd3hKVidN1nd+0+n7XetqOj3nnL2yjc+S7u\neJW6BOm6Owbp3AxGVOPvpg1wYupTbZBCcN3ZsLvHp3lzf4cF/QL8ECRL1W8RwkOdY6QgCJKm\n2NPL0jlfUan7l6rY3UXo2lvT3x5XapBkrx6/BU/ZL0qYiRAzALos72u3s9hnWmyQBl+NWznu\n21leL+0vo2di9qzdB3vs5pUohmyELWrl18h33iD0ZWz8TGhtEdIV+HT+jSDNFHxgZRqkXRp9\ny7hU2JM5hiDNFLwTaRqky3p9mv4I00oUgzHSLOEXnyzHSJcDkw0P8WftBI38Olzxg2Q4a7dn\n1m4o9jqS6/EJyrx8D8huHemjd8bOK4GlSN0LtdDfPbN2iCL4rN242V07Zu2gZMlXpMt+/eZe\njyKFnkzMUcAYacTsrh2TDdBBkAgSFPgGKdo9G2woP8fId8FxLRV6L5t46dfvbR6Gb6OwoVki\n+H3ZXG8B51VJxnNBe/BVp9KsIPVvHf9apXdvHZeX0Hosl900In6lgu9lu8iumJK5Plkv0mqL\n0O1mJt0ntaRGdRpc8ZctOmeO3XW/UmUP5v8iutOqwYtiRpB2aX1Nz0/7mWHn9fjttaQlFB+K\nINUapOG3Txu9fFdoNCNITbcYu03tHSLPb+6vJSyh+FAEqdIgvXyf0kqzPygPUvqP6Q/1poTi\nYzFGKmGMJCD7YAn9GYq5V6RD36eLe0Vi1i5DJUeiMZKohdmsXXvb4fOqu4v+eRN2jHSRzQWx\njlRKKc8dejbrSKeuP7ftCzSqb5St7K/m8lR5RR8/jBlNjuv7AlKz1d0Env20YB7hcCz0Gw/f\nHIRLk4AlYEg4lRbj2iJDkKDPb046jNlB+m4/13zzrXQ4/yyB0qRbf2vq4t30RmLRdn+vb2tI\nH3xin7QEyiPppUknsiX0e5Ezg/SVuo++PCjfBIUgFU4WpOE3W/q9yJlBWj0+jHn0U8rnlPj1\n/we/3VV0Xk9K1rXzC5J0t5Td+5EeD+zxDtnoN2CMznEPxcv3zxr5de0MZhXVrkgOW4Rk12NR\nq6InkP7i96RkQfKbbDCYVSxojDTn2U//nQpKBef5pIR/vdw2+0iOb/z8FTRrR5DmcQ1S8P60\naDLk5fu//1XwgL3vjdc6EkGax/dJSXZXe94gUrBf/OX7v/9V8ICGGCNZCP6kCgj68+sf/yh4\nPFPM2lkwuAGhprK7nlrT343LG/tYR5qDIL3Umn5NMl9HOnmsI2Ge4F078fFpD3dEZgTp+WF9\nLZedDZgh/AyKX9c9VpAuq2GOVD+UIuzvumThgyTrT+svCYlojZF0Bf5dl6uAIAnMWRTRPBMl\nzdphnuhjJBFhkNRnZQnSctQ5p//y/eN2sd7Y5/z5SNGnv6PfvCP68Ul4Xmctp78dgxR9Qdbx\n+ESiH59MkPOn07X7WW+mP860Ehfp3x5RK79Gjn9Rox+flOPbFS9/ngmlMdK5v1Gkln8e1Zz5\nmYmt/Bo5zqVFPz5fUTetOnTtCNI80Y/PU8C3UfS+HN4hS5DmiX58niT9VdMgPeca9tMf6LMS\nr/8vYySp6MfnZ87fFJsx0mOHkOo7zZm1MxH9+PwIg2Q/a6ftrxKsI80T/fi8SPurdutId8dd\n2A8awzyeV6SCP1RJI0in/SrF/cQ+zOM4hvOLbMC9dufv9t0U64PS8fyrBDJynLVznNYId0X6\n7m/HpfpxfReCFEj06fkopeYE6bC9ZqjZHfWvxgQpDII07SEFTZo2Re0bYwlSzYQdrhA3UnAs\nNSNI6f5J5n5Bij79LRN7et5xHW7w1Zj+X4eSrkjRF2Rloi8Yi+IneqEWfdIVxkg/bkEa+bd3\nj1XZH8fgT8pgwVNbsDutes7ayX47olbRu+tVPqnoxp+U0jrSxmEdiSBlaCRDkKY84IPTzgaC\nlKGRkGPX2I19kC5Oe+0YI2VoJFPjlnHTMZIRZu3CNJKqb8s4b6NgHWlWoxozIWT/Ngpl/OIs\n8MY+QwRpORzHmMtDkBbDcdbTV4iuJ0FajEqDJOx6Brv3t5Gwv7WS1RqkwdfPG6kP/AjSclQ5\nRprz52G5QapyTtqtlOzTDoLP2rlu8qhk+rvKVVLXBVnZx4aEGMz/xTFI1SzIOnYyZB1vSaM6\ntwg5XtElz8qgP1hQkByHvZ5/5txKeU4biC5+nlf0wddpbcb/yose0BBBitJIyPWt5qLh4mXy\n8REkeX2CJHN7iU57pYqPz6kXWU2QGCPlaCTiGXS/KahaxkjM2uVoJOIaJEkjkWpm7YQXceEh\n1LeO5Hf+RF27OZdZQUdA+fyVFSQUwvtmeJNHpuoXZ4IEA8K1X/E9smRTPAQJ4Tl+1NHz67Q2\nqq8zgoSy6S8JyQ7DpUnAErAVel6IIKEMwbeMM0ZCGRzXzkWYtRM9WnXrNL6lpnNd3JHhreaT\nH6vCnQPRu05RFnccLSBIkkf0ayQTvOsUZXHHUfVB8tv2ZTAVFKCUTJDFHUcEKW8jmfCvuSCL\nO44IUt5GMgW85kIs7jiqPkiMkYpR9JMKGqT/AWURvMr1g/Mq90kBppr+Ki+sa4e7ortO2liQ\nhVABg3m/916wRQhS4YPkuTNk8FXzEa2bBCyxPPGDNPjqUclkmcW2ScASCxR8jFT2OhxBWo7g\nm0IJkr6/SnC7q3mlQn+quWfXU3hxruR2XNyAcV4px/Mn4rkzRP38FRUkUXm2CM1q5DkF4Nn1\nFN/5q/wgyS79olZ+jWQcj891rq/gt/0SpLyNZGoNUmgEaXorgjSzVY2qCRJjpJmlXMdIoXtp\nMrWMkZi1m1kq+vmLrppZO+mfOdaRZjVSn+BSreSqknUk5OB3+4WiL2MECeMkF5c58xqF/u4J\nEkZVOetpgCBhlN/FhSDpK/NcVslvuEOQ9JV5LuvkNwHHGEmd7vS37BBqnP6WFbpMvrgscPGp\npCDVueApUvRGadVKURQVJK/ywlLRj89P2cMdkYKC5PjbiT59G/2Fmm4Xl6jHZ4AgqZWKfnyO\n0q3rGfX4DBAktVLRj89T8K6ngYKCFH4MEv34/KS76e1MjsdBUUEKPisW/fj8yIIU/EmNKylI\n8ddpoh+fV6lrg9T9b1qrwdfiuAbpZ7/p/k5tdj9WJaBNtNtHMtkQfuA3yjFI51V6WpuUgD7J\ndYIgGTXp7FLzfex+Oh2atLMoAXXSCczp60gE6UNNOj5+PqbGogTUyYIkm2zoB1aT2ogV/EFj\nv458/GkQpDCkQbpMf60WPevJFQnjZGMk2ayd2xVJf4LQd4x0OHU/lTBGin2XHsdGNc7aGZTy\nnP5eD2btVmeTElqqvG+ctD8jWEcKPtlQeJAuP7tuHanZ7KOvI4ku/bL+gl8pvwVPUdeOIOnL\nHSTpnO/0Ro6lPKeXZVdMxkga0pBNic+P5eW7XaNqgyT4NTJr96HzNqX14fYgoae/CdI8ojES\n60gfOjf9Rrv+QUIHiTHSPNGDbsB1+vvrmqavpttmFz1IzNrNQZCMmnSavuGpWZ3CB0l46a9x\nHUlEcvEjSJ+2uzU8r9cFBAlzCGftnl+L4xikVbovwq7WBKl2kpvh+c3a6XMM0lfa3n46pTVB\nqpowE/kXPsQ8p793j9N0eHPGij2d6BXdSxNxXZA9bu4/nbYEqWKydSSuSOqKPZ3o+L4fKUT8\nCBL03V7ZLncRCjJFsYQgRV+nqe/4REESriMFGY7VH6ToOwdqPD7HN/ZFWcZdQJAkj+jXqMrj\nE002ECR9iiVEJ9qvUZ3H5/7XgSCZl6jyhRr9+Fy7noOvGRGkvI3qPL6L42QIs3ZOJWocg4Q/\nPmGQZFhHcilR46yYtJHwM4vc3jUeIhIy9QfJsZcRfB3JM0iDrxMqXSTpi2EJQULPr2vnONUX\nBUFajDonQ6IgSItBkCwRpMVwXUeStRG99yIGgrQcntPzwW8QqY8gLYfr9DxBsmiiVSL29DLH\n92wy+DqhDV07Zf8uEX/BU9Ao/PFJMNlg1ESnhGcf361R+OOTIEhGTVRK1Dl9G/34RPym+sIg\nSHkbhT8+GeFU3/1LgQhS3kbhj09G+DFXbFpVxhgpTCOZ+EEq+PORZpeoc1Ys+vGJRO/a6Zcq\nKUjSPyMVrtMEP750kSwJeV4x1UuVFSTMUeXtuEQMShGk5fAbw3neIFKCIEHOc1aRINk0CVhi\neVyDJOjaMUbSR5AM+K5zSSYbmLXTRpAsRF/nYh1JXanT347cPqNV+Nai6Auy2koKUvQFT0eO\n943zC1L0kz6qqCCJynt2TdxEH5cLG7XZi3vSRxUUJN/BsqCUn+gzxY5TfVEQJL1SfioN0vBb\naQiSXik/dQZJ0iiMgoLEGOmpxjESVyR9zNq9EX3t0m2naxglBUl6lllHmtXIrRSzduoKPZnB\ncZk1RJCWI/7AjyuSskJPZmzRZ8WiH984grQYvi9U0fvTf30vC0FaDM8XqmjW7uV7WQjSctS4\n+BRGWUFynL4VCT69LHtvg1svjVk7ddkXZEWiLxhLP9V8eilpLy364t2IooIkKu/XYYi+hcnv\n+Moe7ogUFCRhf0HUSsLx+PwazWq1oBwRJD0EadCq5OGOCEFSQ5B+tVtUjIoKEmOkHI0W2EsT\nKSpIzNr5N1pgL02kpCBJ+wusI81qFP78hVBWkDBH9CtS0dc+grQc0cdIRY/GCNJi1DnrGQVB\nWgyCZIkgLQZBskSQloMxkiGCtBzM2hkqK0jRPz+HdaR5WEdSprmzQXYAwXcORD8Vy1NUkLzK\nx9/LFv1ULE9BQXKc1RGVcpwVi34qFoggqZUiSEtGkNRKEaQlKyhI4QcGjJEWrKggBZ+qij9r\nJ7sZl6jU0pQUJNaR5jWSRqLg1R0/ZQUJc9BJM0SQFoNpA0sEaTEIkiWCtBgEyRJBWg7GSIYI\n0nIwkW2orCDFnl6u9fjwgZKCFH3BM/rxwVBRQRKV99uCE/34YKigIEXfFBr9+GCJIOVtRJAq\nQZDyNiJIlSgoSOHHINGPD4aKClLwWbHoxwdDJQWp1nUaloQqUFaQgKAIEqCAIAEKCBKggCAB\nCggSoGAJQWL6e1YjfKL+ILEgO6sRPrOAIEkescotQuwrMlR9kNi0OqsRPkSQ8jYKf3z4DEHK\n2yj88eEz1Qcp/Bgk+vHhIwsIUvBZsejHh4/UH6T46zTRjw8fWEKQAHMECVBAkAAFBAlQQJAA\nBQQJULCEIDG9DHP1B4kFTzhYQJAkj8gWHExTfZDYFAoPBClvI1SCIOVthEpUHyTGSPCwgCAx\nawd79QeJdSQ4WEKQAHMECVBAkAAFBAlQQJAABQQJUECQAAVlBclxnYZ1JExRUpAcdw6wswHT\nFBUkr/LstcNUBQXJcXc1u78xEUFSK0WQlowgqZUiSEtWUJAYIyGuooLErB2iKilIrCMhLNcg\n/ew3qbXZ/ViVALJwDNJ5lZ7WJiWATByDtEvN97H76XRo0s6iBJCJY5CadHz8fEyNRQkgE8cg\n/RqIj4/KCRIKwxUJUOA7Rjqcup/EYySmlxGU5/T3ejBrtzpPL8GCJ8LyXUfadetIzWYvWkdi\nCw7CKmhnA5tCEVecIKWhsboECfHECdLbEgQJcRUUJMZIiKuoIDFrh6hcdza8HQa9K8E6EoJy\nDNLX/CABQXl27Y7N+JsnFEoAebiOkY7jG4M0SgBZ+E42fA32rRqVAHIoadYOCIsgAQrKChLT\n3wiqpCCxIIuwigqSV3lgqoKCxKZVxEWQAAUECVBQUJAYIyGuooLErB2iKilIrCMhrLKCBARF\nkAAFBAlQQJAABQQJUECQAAUECVBAkAAFBAlQQJAABQQJUECQAAUECVBAkAAFBAlQQJAABQQJ\nUECQAAVBgwQURvAq1w9OxNpVlqrySZV6/ghSuaWqfFKlnj+CVG6pKp9UqeePIJVbqsonVer5\nI0jllqrySZV6/ghSuaWqfFKlnj+CVG6pKp9UqeePIJVbqsonVer5I0jllqrySZV6/ghSuaWq\nfFKlnj+CVG6pKp9UqeePIJVbqsonVer5Y2s2oIAgAQoIEqCAIAEKCBKggCABCggSoIAgAQoI\nEqCAIAEKCBKggCABCggSoIAgAQoIEqCAIAEK/IP060bluyY1u7NLqa+VW6mrH7MT+6vScZvS\n9uRR6mz7q/r1+LalhpX0XhT5gtRcf153P608Su36n6x+PcNSV+fGPEhtpYPbkzo1/U9WoR0+\nvu2rYlhJ8UWRq2t3SD/tn+3meDk27Y/WpY5pez1dX2lrX6q1kXwyyPRKzfX8nTdpZ19q2xXZ\nmZ2/weMbvyoGlTRfFJmCdG42l/bZHK5fv9PevtSmf6K2r+++1KV9SsZB6it9d6+J8/0yaFkq\nGZ+/weMbvyoGlTRfFJmCtEnn7mt7fT2mjX2pG9vX973UKa2Ng9RX2qajaZVBqVtX1Syzg8c3\nflX895kUHKRj3xux/jM3KNU7p7VHqXU62QbpVmmVLvum656Yl9rfOkRWnYfB4xu/Kv7zTHRe\nFHmCdPvT7RGkXxekr67XYF1qn759Ln0pbQYTHKalLl/tGL35MqvzfHzrV8XrM9F5UWQJ0vE2\nvHMI0nE4kjw1lp3Ie6muU2J8lb2fv3ayYWs5xnycv303wWVX6fn41q+Kl2ei9KLIEqTd7W+A\nQ5B2gz8358ayY/cotWqnU02D9Dx/7RjpZLd+8Cz11XaIrpm1uiQNHt/4VfHyTLReFFmCdF9k\naeyDNFzPWRu+4J6ltt1LzzRI9yfl8IfoXmrV9fDOZpkdPL7xq+LlmWi9KHIE6TEh08/PnAxn\n7QZzP6fV2mwLwLDUnM+Yn1bJYU7/Ucpx+tv4VfHrmei9KHIE6et+Wd13f7wPhguKj1LXKqb9\nugvfTf8AAAPTSURBVGcp+yC9nL+T4TN7lOovE3ZLVoPHN35VDJ+J4osiR5A29+UP+50Nj1KW\nr7aXUh3L7tbgSa3ObXf/277ULrVb0nZmf/MGj2/8qhhU0nxR5AjS6jEjver+chu+xB+lttaX\nicGzalkG6Vlp73b+bhvg7EoNHt/4VfGspPmiyBGk54H3G3E9Spn3t16iYxmkwWMf1k7n77Yl\n27DU8/GtXxWPh9d8UfB+JEABQQIUECRAAUECFBAkQAFBAhQQJEABQQIUECRAAUECFBAkQAFB\nAhQQJEABQQIUECRAAUECFBAkQAFBAhQQJEABQQIUECRAAUECFBAkQAFBAhQQJEABQQIUECRA\nAUECFBAkQAFBAhQQJEABQQIUEKRy8bsLhF9GPM0/PvL48Pp/nLbt586d//MfIg+CFM4hpfSa\nm9Xr7+nYf2aj1YeMYyqCFM427dL25f/7z8ecrtPunM5rs08Zx0QEKZzrZaZ5/bX8J0jt/5Eu\nZy5JURCkaL6vV5ld+m5/7ONz/fr46O2vVVp9tT806dz/7s5pdXl+v/570/375bBJj8/uPq/S\nxvlZLA5Bimadfi4/ad3++J8grbsf2n/bpdWh/91trv/9pc3fvv35/u/7fgy169pvEl1AawQp\nmL631l5wBkG6/fSdmuPl2HSXq+01Jts2Qod+QLVNp+uP6/PlOnA6tA2+2/8+de3XTO6ZI0jB\nfHcXj75v9xqkTTebd+gvV8fdNUptj23Vh27V/nv70/nZj7sF6cf5OSwRQQpm1b3sj92I5zVI\ntymH+8xDOqzSdUD01Xbqftov6a7919Nhv74Fyf9ZLA8nOZbTIwyn90HqZxi6zuC+/++fQVo/\nfiJIHjjJsewfYdh/EKT+x921x7daXX5FZptWX4cTQXLDSY5l1V5ZLu2VaXWLwM9/x0ib+/R3\nPzNxTOtjm7vbv3e6BgTJDyc5lONjomCdjpd2CHRe90Fq8zWYtdumzXNnwyo1z3+/jpk2/QzD\nkTGSH05yKLvHNeVwzchX28XbtEFY9dvqnutI52aw1+6Qbquy/b83p/aBej8EyQcnOZSm+fXj\nvknbLgg/qz4zX81tZ8PltHvu/j53I6ru36+J23adw+01cD+H/uLk+hQWipNcrsfv7pBuIytk\nQ5DK9fjdrdNXzuPAhSBV4DZqQlYEqXgNW7sDIEiAAoIEKCBIgAKCBCggSIACggQoIEiAAoIE\nKCBIgAKCBCggSIACggQoIEiAAoIEKCBIgAKCBCggSIACggQoIEiAAoIEKCBIgAKCBCggSIAC\nggQoIEiAAoIEKCBIgIL/A5U9mDbRqpdvAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(Auto$year, Auto$mpg)\n",
    "abline(h = median(Auto$mpg), lwd = 2, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the above scatterplot of `mpg` vs `year` also shows that the newer cars in the data set tend to be more fuel efficient. Therefore, while manufacture year might not be as useful as the other four quantitative variables, that stood out (`cylinders`, `displacement`, `horsepower` and `weight`), it still seems worth including."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\nkAABQgIE/gcvGfdrTvRgJQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(Auto$origin, Auto$mpg, xlab = \"Origin\", ylab = \"MPG\")\n",
    "abline(h = median(Auto$mpg), lwd = 2, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, when looking at a boxplot that compares the mpg values for each car, categorized by country of origin, we see that there is a clear difference between American cars, which tend to have below-median fuel efficiency, and European and Japanese cars, which tend to have above-median fuel efficiency. Thus, it seems that `origin` will also be useful in predicting `mpg01`. \n",
    "\n",
    "In conclusion, for the remaining parts I will use all of the predictors except for `acceleration` and `name` to in my models for trying to predict `mpg01`. Also, I will exclude `mpg` because that was directly used to create the classification label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "**Split the data into a training set and a test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split my data into a training set and a test set, I will use the `sample()` function to do a 75%-25% split. In other words, I will use 75% of the data (294 observations) for the training set and the remaining 25% (98 observations) for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "train = sample(dim(Auto)[1], size = 0.75*dim(Auto)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "\n",
    "**Perform LDA on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in Part 2. What is the test error of the model obtained?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit = lda(mpg01 ~ cylinders + displacement + horsepower + weight + year + origin, data = Auto, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted  0  1\n",
       "        0 41  0\n",
       "        1 12 45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda.pred = predict(lda.fit, Auto[-train, ])\n",
    "table(lda.pred$class, Auto[-train, \"mpg01\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.122448979591837"
      ],
      "text/latex": [
       "0.122448979591837"
      ],
      "text/markdown": [
       "0.122448979591837"
      ],
      "text/plain": [
       "[1] 0.122449"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(lda.pred$class == Auto[-train, \"mpg01\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using linear discriminant analysis to predict `mpg01` using `cylinders`, `displacement`, `horsepower`, `weight`, `year`, and `origin`, we had an overall test error of 12.24%. One thing of note is that this method didn't mis-classify any of the cars that actually had above-median fuel economy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit = lda(mpg01 ~ cylinders + displacement + horsepower + weight, data = Auto, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted  0  1\n",
       "        0 42  2\n",
       "        1 11 43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda.pred = predict(lda.fit, Auto[-train, ])\n",
    "table(lda.pred$class, Auto[-train, \"mpg01\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.13265306122449"
      ],
      "text/latex": [
       "0.13265306122449"
      ],
      "text/markdown": [
       "0.13265306122449"
      ],
      "text/plain": [
       "[1] 0.1326531"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(lda.pred$class == Auto[-train, \"mpg01\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we exclude the `origin` and `year` variables, our overall test error increases very slightly to 13.27%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "\n",
    "**Perform QDA on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in Part 2. What is the test error of the model obtained?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.fit = qda(mpg01 ~ cylinders + displacement + horsepower + weight + year + origin, data = Auto, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted  0  1\n",
       "        0 42  2\n",
       "        1 11 43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.pred = predict(qda.fit, Auto[-train, ])\n",
    "table(qda.pred$class, Auto[-train, \"mpg01\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.13265306122449"
      ],
      "text/latex": [
       "0.13265306122449"
      ],
      "text/markdown": [
       "0.13265306122449"
      ],
      "text/plain": [
       "[1] 0.1326531"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(qda.pred$class == Auto[-train, \"mpg01\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using quadratic discriminant analysis to predict `mpg01` using `cylinders`, `displacement`, `horsepower`, `weight`, `year`, and `origin`, we had an overall test error of 13.27%, which is the same performance as linear discriminant analysis using all of those predictors aside from `year` and `origin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.fit = qda(mpg01 ~ cylinders + displacement + horsepower + weight, data = Auto, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted  0  1\n",
       "        0 45  4\n",
       "        1  8 41"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.pred = predict(qda.fit, Auto[-train, ])\n",
    "table(qda.pred$class, Auto[-train, \"mpg01\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.122448979591837"
      ],
      "text/latex": [
       "0.122448979591837"
      ],
      "text/markdown": [
       "0.122448979591837"
      ],
      "text/plain": [
       "[1] 0.122449"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(qda.pred$class == Auto[-train, \"mpg01\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we exclude the `origin` and `year` variables, our overall test error decreases down to 12.24%. This is the same performance as linear discriminant analysis using all of the original predictors, though this model has a different confusion matrix. In particular, using the convention that above-median mpg is the positive class label, this model has a lower false positive rate ($8/53 \\approx 0.151$ versus $12/53 \\approx 0.226$), a lower true positive rate ($41/45 \\approx 0.911$ versus $45/45 = 1$), a higher positive predictive value ($41/49 \\approx 0.837$ versus $45/57 \\approx 0.789$), and a lower negative predictive value ($45/49 \\approx 0.918$ versus $41/41 = 1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6\n",
    "**Perform logistic regression on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in Part 2. What is the test error of the model obtained?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = mpg01 ~ cylinders + displacement + horsepower + \n",
       "    weight + year + origin, family = \"binomial\", data = Auto, \n",
       "    subset = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-2.41776  -0.08516   0.01173   0.19819   2.84514  \n",
       "\n",
       "Coefficients:\n",
       "                 Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)    -20.936182   6.060143  -3.455 0.000551 ***\n",
       "cylinders       -0.059473   0.492704  -0.121 0.903923    \n",
       "displacement     0.016274   0.014742   1.104 0.269631    \n",
       "horsepower      -0.041375   0.021078  -1.963 0.049645 *  \n",
       "weight          -0.006170   0.001471  -4.193 2.75e-05 ***\n",
       "year             0.517975   0.103270   5.016 5.28e-07 ***\n",
       "originEuropean   2.627520   0.962636   2.730 0.006343 ** \n",
       "originJapanese   0.906254   0.781956   1.159 0.246473    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 407.35  on 293  degrees of freedom\n",
       "Residual deviance: 116.63  on 286  degrees of freedom\n",
       "AIC: 132.63\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(mpg01 ~ cylinders + displacement + horsepower + weight + year + origin, data = Auto, subset = train,\n",
    "             family = \"binomial\")\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted  0  1\n",
       "        0 45  1\n",
       "        1  8 44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.probs = predict(glm.fit, Auto[-train, ], type = \"response\")\n",
    "glm.pred = rep(0, dim(Auto[-train, ])[1])\n",
    "glm.pred[glm.probs > 0.5] = 1\n",
    "table(glm.pred, Auto[-train, \"mpg01\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0918367346938775"
      ],
      "text/latex": [
       "0.0918367346938775"
      ],
      "text/markdown": [
       "0.0918367346938775"
      ],
      "text/plain": [
       "[1] 0.09183673"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(glm.pred == Auto[-train, \"mpg01\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using logistic regression to predict `mpg01` using `cylinders`, `displacement`, `horsepower`, `weight`, `year`, and `origin`, we had an overall test error of 9.18%, the best test error out of the methods we've explored so far in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = mpg01 ~ cylinders + displacement + horsepower + \n",
       "    weight, family = \"binomial\", data = Auto, subset = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4446  -0.1835   0.1355   0.4263   3.2094  \n",
       "\n",
       "Coefficients:\n",
       "               Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  11.1147950  1.9486579   5.704 1.17e-08 ***\n",
       "cylinders     0.0188859  0.4031908   0.047   0.9626    \n",
       "displacement -0.0123198  0.0094472  -1.304   0.1922    \n",
       "horsepower   -0.0357577  0.0162188  -2.205   0.0275 *  \n",
       "weight       -0.0019561  0.0007808  -2.505   0.0122 *  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 407.35  on 293  degrees of freedom\n",
       "Residual deviance: 161.44  on 289  degrees of freedom\n",
       "AIC: 171.44\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(mpg01 ~ cylinders + displacement + horsepower + weight, data = Auto, subset = train,\n",
    "             family = \"binomial\")\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted  0  1\n",
       "        0 45  2\n",
       "        1  8 43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.probs = predict(glm.fit, Auto[-train, ], type = \"response\")\n",
    "glm.pred = rep(0, dim(Auto[-train, ])[1])\n",
    "glm.pred[glm.probs > 0.5] = 1\n",
    "table(glm.pred, Auto[-train, \"mpg01\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.102040816326531"
      ],
      "text/latex": [
       "0.102040816326531"
      ],
      "text/markdown": [
       "0.102040816326531"
      ],
      "text/plain": [
       "[1] 0.1020408"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(glm.pred == Auto[-train, \"mpg01\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we exclude the `origin` and `year` variables, our overall test error increases very slightly, with one additional mis-classified prediction, to 10.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7\n",
    "**Perform KNN on the training data, with several values of $K$, in order to predict `mpg01`. Use only the variables that seemed most associated with `mpg01` in Part 2. What test errors did you obtain? Which value of $K$ seems to perform the best on this data set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try out $k = 1, 3, 5, \\dots, 19$ when using $k$-nearest neighbors. As I did in the previous parts, I will first use `cylinders`, `displacement`, `horsepower`, `weight`, and `year` as the predictors. I will, however, exclude `origin` as it is a qualitative variable. I could convert it back to a numerical encoding, but then I would need to be careful to make sure each value is equidistant from the others. I also need to be careful of the different scales used to measure the various predictors, since variables such as `weights` are on the order of thousands of pounds while `displacement` is on the order of tens or hundreds of cubic inches. In order to put all of the quantitative variables on a comparable scale, I will standardize them so that all of them have mean zero and standard deviation one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>mpg</th><th scope=col>cylinders</th><th scope=col>displacement</th><th scope=col>horsepower</th><th scope=col>weight</th><th scope=col>acceleration</th><th scope=col>year</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.6977467</td><td>1.482053  </td><td>1.075915  </td><td>0.6632851 </td><td>0.6197483 </td><td>-1.283618 </td><td>-1.623241 </td></tr>\n",
       "\t<tr><td>-1.0821153</td><td>1.482053  </td><td>1.486832  </td><td>1.5725848 </td><td>0.8422577 </td><td>-1.464852 </td><td>-1.623241 </td></tr>\n",
       "\t<tr><td>-0.6977467</td><td>1.482053  </td><td>1.181033  </td><td>1.1828849 </td><td>0.5396921 </td><td>-1.646086 </td><td>-1.623241 </td></tr>\n",
       "\t<tr><td>-0.9539925</td><td>1.482053  </td><td>1.047246  </td><td>1.1828849 </td><td>0.5361602 </td><td>-1.283618 </td><td>-1.623241 </td></tr>\n",
       "\t<tr><td>-0.8258696</td><td>1.482053  </td><td>1.028134  </td><td>0.9230850 </td><td>0.5549969 </td><td>-1.827320 </td><td>-1.623241 </td></tr>\n",
       "\t<tr><td>-1.0821153</td><td>1.482053  </td><td>2.241772  </td><td>2.4299245 </td><td>1.6051468 </td><td>-2.008554 </td><td>-1.623241 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " mpg & cylinders & displacement & horsepower & weight & acceleration & year\\\\\n",
       "\\hline\n",
       "\t -0.6977467 & 1.482053   & 1.075915   & 0.6632851  & 0.6197483  & -1.283618  & -1.623241 \\\\\n",
       "\t -1.0821153 & 1.482053   & 1.486832   & 1.5725848  & 0.8422577  & -1.464852  & -1.623241 \\\\\n",
       "\t -0.6977467 & 1.482053   & 1.181033   & 1.1828849  & 0.5396921  & -1.646086  & -1.623241 \\\\\n",
       "\t -0.9539925 & 1.482053   & 1.047246   & 1.1828849  & 0.5361602  & -1.283618  & -1.623241 \\\\\n",
       "\t -0.8258696 & 1.482053   & 1.028134   & 0.9230850  & 0.5549969  & -1.827320  & -1.623241 \\\\\n",
       "\t -1.0821153 & 1.482053   & 2.241772   & 2.4299245  & 1.6051468  & -2.008554  & -1.623241 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| mpg | cylinders | displacement | horsepower | weight | acceleration | year |\n",
       "|---|---|---|---|---|---|---|\n",
       "| -0.6977467 | 1.482053   | 1.075915   | 0.6632851  | 0.6197483  | -1.283618  | -1.623241  |\n",
       "| -1.0821153 | 1.482053   | 1.486832   | 1.5725848  | 0.8422577  | -1.464852  | -1.623241  |\n",
       "| -0.6977467 | 1.482053   | 1.181033   | 1.1828849  | 0.5396921  | -1.646086  | -1.623241  |\n",
       "| -0.9539925 | 1.482053   | 1.047246   | 1.1828849  | 0.5361602  | -1.283618  | -1.623241  |\n",
       "| -0.8258696 | 1.482053   | 1.028134   | 0.9230850  | 0.5549969  | -1.827320  | -1.623241  |\n",
       "| -1.0821153 | 1.482053   | 2.241772   | 2.4299245  | 1.6051468  | -2.008554  | -1.623241  |\n",
       "\n"
      ],
      "text/plain": [
       "  mpg        cylinders displacement horsepower weight    acceleration year     \n",
       "1 -0.6977467 1.482053  1.075915     0.6632851  0.6197483 -1.283618    -1.623241\n",
       "2 -1.0821153 1.482053  1.486832     1.5725848  0.8422577 -1.464852    -1.623241\n",
       "3 -0.6977467 1.482053  1.181033     1.1828849  0.5396921 -1.646086    -1.623241\n",
       "4 -0.9539925 1.482053  1.047246     1.1828849  0.5361602 -1.283618    -1.623241\n",
       "5 -0.8258696 1.482053  1.028134     0.9230850  0.5549969 -1.827320    -1.623241\n",
       "6 -1.0821153 1.482053  2.241772     2.4299245  1.6051468 -2.008554    -1.623241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled.auto = scale(Auto[, -c(8, 9, 10)])\n",
    "head(scaled.auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = c(\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"year\")\n",
    "train.X = scaled.auto[train, cols]\n",
    "test.X = scaled.auto[-train, cols]\n",
    "train.mpg01 = Auto[train, \"mpg01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>k.vals</th><th scope=col>knn.error</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1        </td><td>0.05102041</td></tr>\n",
       "\t<tr><td> 3        </td><td>0.07142857</td></tr>\n",
       "\t<tr><td> 5        </td><td>0.07142857</td></tr>\n",
       "\t<tr><td> 7        </td><td>0.08163265</td></tr>\n",
       "\t<tr><td> 9        </td><td>0.08163265</td></tr>\n",
       "\t<tr><td>11        </td><td>0.10204082</td></tr>\n",
       "\t<tr><td>13        </td><td>0.11224490</td></tr>\n",
       "\t<tr><td>15        </td><td>0.11224490</td></tr>\n",
       "\t<tr><td>17        </td><td>0.10204082</td></tr>\n",
       "\t<tr><td>19        </td><td>0.10204082</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " k.vals & knn.error\\\\\n",
       "\\hline\n",
       "\t  1         & 0.05102041\\\\\n",
       "\t  3         & 0.07142857\\\\\n",
       "\t  5         & 0.07142857\\\\\n",
       "\t  7         & 0.08163265\\\\\n",
       "\t  9         & 0.08163265\\\\\n",
       "\t 11         & 0.10204082\\\\\n",
       "\t 13         & 0.11224490\\\\\n",
       "\t 15         & 0.11224490\\\\\n",
       "\t 17         & 0.10204082\\\\\n",
       "\t 19         & 0.10204082\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| k.vals | knn.error |\n",
       "|---|---|\n",
       "|  1         | 0.05102041 |\n",
       "|  3         | 0.07142857 |\n",
       "|  5         | 0.07142857 |\n",
       "|  7         | 0.08163265 |\n",
       "|  9         | 0.08163265 |\n",
       "| 11         | 0.10204082 |\n",
       "| 13         | 0.11224490 |\n",
       "| 15         | 0.11224490 |\n",
       "| 17         | 0.10204082 |\n",
       "| 19         | 0.10204082 |\n",
       "\n"
      ],
      "text/plain": [
       "      k.vals knn.error \n",
       " [1,]  1     0.05102041\n",
       " [2,]  3     0.07142857\n",
       " [3,]  5     0.07142857\n",
       " [4,]  7     0.08163265\n",
       " [5,]  9     0.08163265\n",
       " [6,] 11     0.10204082\n",
       " [7,] 13     0.11224490\n",
       " [8,] 15     0.11224490\n",
       " [9,] 17     0.10204082\n",
       "[10,] 19     0.10204082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "k.vals = (1:10)*2 - 1\n",
    "knn.error = rep(0, 10)\n",
    "knn.tables = list()\n",
    "for (i in 1:10){\n",
    "    knn.pred = knn(train.X, test.X, train.mpg01, k = 2*i - 1)\n",
    "    knn.tables[[k.vals[i]]] = table(knn.pred, Auto[-train, \"mpg01\"], dnn = c(\"Predicted\", \"Actual\"))\n",
    "    knn.error[i] = 1 - mean(knn.pred == Auto[-train, \"mpg01\"])\n",
    "}\n",
    "cbind(k.vals, knn.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted  0  1\n",
       "        0 48  0\n",
       "        1  5 45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn.tables[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that $k = 1$ has the lowest test error, with a value of 5.1%. Inspecting the confusion matrix for $k = 1$, which I stored in the list `knn.tables`, we also observe that all of the errors were false positives -- that is cars the model classified as having above-median fuel efficiency which actually were in the below-median group.\n",
    "\n",
    "Next, I will exclude the `year` variable as I did in the previous parts to see how the test errors change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = c(\"cylinders\", \"displacement\", \"horsepower\", \"weight\")\n",
    "train.X = scaled.auto[train, cols]\n",
    "test.X = scaled.auto[-train, cols]\n",
    "train.mpg01 = Auto[train, \"mpg01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>k.vals</th><th scope=col>knn.error</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1       </td><td>0.1020408</td></tr>\n",
       "\t<tr><td> 3       </td><td>0.1326531</td></tr>\n",
       "\t<tr><td> 5       </td><td>0.1428571</td></tr>\n",
       "\t<tr><td> 7       </td><td>0.1326531</td></tr>\n",
       "\t<tr><td> 9       </td><td>0.1428571</td></tr>\n",
       "\t<tr><td>11       </td><td>0.1122449</td></tr>\n",
       "\t<tr><td>13       </td><td>0.1122449</td></tr>\n",
       "\t<tr><td>15       </td><td>0.1122449</td></tr>\n",
       "\t<tr><td>17       </td><td>0.1122449</td></tr>\n",
       "\t<tr><td>19       </td><td>0.1122449</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " k.vals & knn.error\\\\\n",
       "\\hline\n",
       "\t  1        & 0.1020408\\\\\n",
       "\t  3        & 0.1326531\\\\\n",
       "\t  5        & 0.1428571\\\\\n",
       "\t  7        & 0.1326531\\\\\n",
       "\t  9        & 0.1428571\\\\\n",
       "\t 11        & 0.1122449\\\\\n",
       "\t 13        & 0.1122449\\\\\n",
       "\t 15        & 0.1122449\\\\\n",
       "\t 17        & 0.1122449\\\\\n",
       "\t 19        & 0.1122449\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| k.vals | knn.error |\n",
       "|---|---|\n",
       "|  1        | 0.1020408 |\n",
       "|  3        | 0.1326531 |\n",
       "|  5        | 0.1428571 |\n",
       "|  7        | 0.1326531 |\n",
       "|  9        | 0.1428571 |\n",
       "| 11        | 0.1122449 |\n",
       "| 13        | 0.1122449 |\n",
       "| 15        | 0.1122449 |\n",
       "| 17        | 0.1122449 |\n",
       "| 19        | 0.1122449 |\n",
       "\n"
      ],
      "text/plain": [
       "      k.vals knn.error\n",
       " [1,]  1     0.1020408\n",
       " [2,]  3     0.1326531\n",
       " [3,]  5     0.1428571\n",
       " [4,]  7     0.1326531\n",
       " [5,]  9     0.1428571\n",
       " [6,] 11     0.1122449\n",
       " [7,] 13     0.1122449\n",
       " [8,] 15     0.1122449\n",
       " [9,] 17     0.1122449\n",
       "[10,] 19     0.1122449"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "k.vals = (1:10)*2 - 1\n",
    "knn.error = rep(0, 10)\n",
    "knn.tables = list()\n",
    "for (i in 1:10){\n",
    "    knn.pred = knn(train.X, test.X, train.mpg01, k = 2*i - 1)\n",
    "    knn.tables[[k.vals[i]]] = table(knn.pred, Auto[-train, \"mpg01\"], dnn = c(\"Predicted\", \"Actual\"))\n",
    "    knn.error[i] = 1 - mean(knn.pred == Auto[-train, \"mpg01\"])\n",
    "}\n",
    "cbind(k.vals, knn.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted  0  1\n",
       "        0 47  4\n",
       "        1  6 41"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn.tables[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I excluded the `year` variable, the model generally performed worse, especially for lower values of $k$. In this case, the lowest test error was still with $k = 1$, but it has doubled to 10.2%. Looking at the confusion matrix, we can see that most of the additional errors came from mis-classifying cars that actually had above-median fuel efficiency and placing them in the below-median group.\n",
    "\n",
    "In conclusion, using $k$-nearest neighbors with $k = 1$ and `cylinders`, `displacement`, `horsepower`, `weight`, and `year` as the predictors provided the lowest overall error on our held-out test set. We should be careful and gather more evidence by using cross-validation in order to better evaluate this model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 3\n",
    "\n",
    "**This problem involves writing functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "**Write a function, `Power()`, that prints out the result of raising 2 to the 3rd power. In other words, your function should compute $2^3$ and print out the results.**\n",
    "\n",
    "***Hint: Recall that `x^a` raises `x` to the power `a`. Use the `print()` function to output the result.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power = function(){\n",
    "    print(2^3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 8\n"
     ]
    }
   ],
   "source": [
    "Power()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "**Create a new function, `Power2()` that allows you to pass *any* two numbers, `x` and `a`, and prints out the value of `x^a`. You can do this by beginning your function with the line**\n",
    "\n",
    "```\n",
    "> Power2 = function(x, a){\n",
    "```\n",
    "\n",
    "**You should be able to call your function by entering, for instance,**\n",
    "\n",
    "```\n",
    "> Power2(3, 8)\n",
    "```\n",
    "\n",
    "**in a notebook cell. This should output the value $3^8$, namely 6,561.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power2 = function(x, a){\n",
    "    print(x^a)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6561\n"
     ]
    }
   ],
   "source": [
    "Power2(3, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "**Using the `Power2()` function that you just wrote, compute $10^3$, $8^{17}$, and $131^3$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1000\n"
     ]
    }
   ],
   "source": [
    "Power2(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2.2518e+15\n"
     ]
    }
   ],
   "source": [
    "Power2(8, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2248091\n"
     ]
    }
   ],
   "source": [
    "Power2(131, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "**Now create a new function, `Power3()`, that actually *returns* the result `x^a` as an `R` object, rather than simply printing it to the screen. That is, if you store the value `x^a` in an object called `result` within your function, then you can simply `return()` this result using the following line:**\n",
    "\n",
    "```\n",
    "return(result)\n",
    "```\n",
    "\n",
    "**The line above should be the last line in your function, before the `}` symbol.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Power3 = function(x, a){\n",
    "    return(x^a)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Power3(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "125"
      ],
      "text/latex": [
       "125"
      ],
      "text/markdown": [
       "125"
      ],
      "text/plain": [
       "[1] 125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "**Now using the `Power3()` function, create a plot of $f(x) = x^2$. The $x$-axis should display a range of integers from 1 to 10, and the $y$-axis should display $x^2$. Label the axes appropriately, and use an appropriate title for the figure. Consider displaying either the $x$-axis, the $y$-axis, or both axes on the log-scale. You can do this by using `log = \"x\"`, `log = \"y\"`, or `log = \"xy\"` as arguments to the `plot()` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQYCQIEBIECAkCBASBAgJAoQEAUKCgP8A/gZXSktMx5YAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Plot of x vs x^2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(1:10, Power3(1:10, 2), xlab = \"x\", ylab = \"f(x)\", main = \"Plot of x vs x^2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nMOgccl9WAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"Log-scale plot of x vs x^2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(1:10, Power3(1:10, 2), xlab = \"x\", ylab = \"f(x)\", main = \"Log-scale plot of x vs x^2\", log = \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6\n",
    "**Create a function, `PlotPower()` that allows you to create a plot of `x` against `x^a` for a fixed `a` and for a range of values of `x`. For instance, if you call**\n",
    "\n",
    "```\n",
    "> PlotPower(1:10, 3)\n",
    "```\n",
    "\n",
    "**then a plot should be created with an $x$-axis taking on values $1, 2, \\dots, 10$, and a $y$-axis taking on values $1^3, 2^3, \\dots, 10^3$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotPower = function(x, a, log = \"\"){\n",
    "    plot(x, x^a, xlab = \"x\", ylab = paste(\"x^\", a, sep = \"\"), log = log)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nAUKCACFBgJAgQEgQICQIEBIECAkC/gfmdHwu3A8ulAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PlotPower(1:10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added the `log` argument so the user can specify if they want to use a logarithmically scaled on either or both axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PlotPower(1:10, 3, log = \"xy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 4\n",
    "**Using the `Boston` data set, fit classification models in order to predict whether a given suburb has a crime rate above or below the median. Explore logistic regression, LDA, and KNN models using various subsets of the predictors. Describe your findings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have consistency with my results for when I do these exercises in Python, I'll use the corrected Boston housing data set instead of the one that is part of the `MASS` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>CMEDV</th><th scope=col>CRIM</th><th scope=col>ZN</th><th scope=col>INDUS</th><th scope=col>CHAS</th><th scope=col>NOX</th><th scope=col>RM</th><th scope=col>AGE</th><th scope=col>DIS</th><th scope=col>RAD</th><th scope=col>TAX</th><th scope=col>PTRATIO</th><th scope=col>B</th><th scope=col>LSTAT</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>24.0   </td><td>0.00632</td><td>18     </td><td>2.31   </td><td>0      </td><td>0.538  </td><td>6.575  </td><td>65.2   </td><td>4.0900 </td><td>1      </td><td>296    </td><td>15.3   </td><td>396.90 </td><td>4.98   </td></tr>\n",
       "\t<tr><td>21.6   </td><td>0.02731</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>6.421  </td><td>78.9   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>396.90 </td><td>9.14   </td></tr>\n",
       "\t<tr><td>34.7   </td><td>0.02729</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>7.185  </td><td>61.1   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>392.83 </td><td>4.03   </td></tr>\n",
       "\t<tr><td>33.4   </td><td>0.03237</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.998  </td><td>45.8   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.63 </td><td>2.94   </td></tr>\n",
       "\t<tr><td>36.2   </td><td>0.06905</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>7.147  </td><td>54.2   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>396.90 </td><td>5.33   </td></tr>\n",
       "\t<tr><td>28.7   </td><td>0.02985</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.430  </td><td>58.7   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.12 </td><td>5.21   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllll}\n",
       " CMEDV & CRIM & ZN & INDUS & CHAS & NOX & RM & AGE & DIS & RAD & TAX & PTRATIO & B & LSTAT\\\\\n",
       "\\hline\n",
       "\t 24.0    & 0.00632 & 18      & 2.31    & 0       & 0.538   & 6.575   & 65.2    & 4.0900  & 1       & 296     & 15.3    & 396.90  & 4.98   \\\\\n",
       "\t 21.6    & 0.02731 &  0      & 7.07    & 0       & 0.469   & 6.421   & 78.9    & 4.9671  & 2       & 242     & 17.8    & 396.90  & 9.14   \\\\\n",
       "\t 34.7    & 0.02729 &  0      & 7.07    & 0       & 0.469   & 7.185   & 61.1    & 4.9671  & 2       & 242     & 17.8    & 392.83  & 4.03   \\\\\n",
       "\t 33.4    & 0.03237 &  0      & 2.18    & 0       & 0.458   & 6.998   & 45.8    & 6.0622  & 3       & 222     & 18.7    & 394.63  & 2.94   \\\\\n",
       "\t 36.2    & 0.06905 &  0      & 2.18    & 0       & 0.458   & 7.147   & 54.2    & 6.0622  & 3       & 222     & 18.7    & 396.90  & 5.33   \\\\\n",
       "\t 28.7    & 0.02985 &  0      & 2.18    & 0       & 0.458   & 6.430   & 58.7    & 6.0622  & 3       & 222     & 18.7    & 394.12  & 5.21   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| CMEDV | CRIM | ZN | INDUS | CHAS | NOX | RM | AGE | DIS | RAD | TAX | PTRATIO | B | LSTAT |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 24.0    | 0.00632 | 18      | 2.31    | 0       | 0.538   | 6.575   | 65.2    | 4.0900  | 1       | 296     | 15.3    | 396.90  | 4.98    |\n",
       "| 21.6    | 0.02731 |  0      | 7.07    | 0       | 0.469   | 6.421   | 78.9    | 4.9671  | 2       | 242     | 17.8    | 396.90  | 9.14    |\n",
       "| 34.7    | 0.02729 |  0      | 7.07    | 0       | 0.469   | 7.185   | 61.1    | 4.9671  | 2       | 242     | 17.8    | 392.83  | 4.03    |\n",
       "| 33.4    | 0.03237 |  0      | 2.18    | 0       | 0.458   | 6.998   | 45.8    | 6.0622  | 3       | 222     | 18.7    | 394.63  | 2.94    |\n",
       "| 36.2    | 0.06905 |  0      | 2.18    | 0       | 0.458   | 7.147   | 54.2    | 6.0622  | 3       | 222     | 18.7    | 396.90  | 5.33    |\n",
       "| 28.7    | 0.02985 |  0      | 2.18    | 0       | 0.458   | 6.430   | 58.7    | 6.0622  | 3       | 222     | 18.7    | 394.12  | 5.21    |\n",
       "\n"
      ],
      "text/plain": [
       "  CMEDV CRIM    ZN INDUS CHAS NOX   RM    AGE  DIS    RAD TAX PTRATIO B     \n",
       "1 24.0  0.00632 18 2.31  0    0.538 6.575 65.2 4.0900 1   296 15.3    396.90\n",
       "2 21.6  0.02731  0 7.07  0    0.469 6.421 78.9 4.9671 2   242 17.8    396.90\n",
       "3 34.7  0.02729  0 7.07  0    0.469 7.185 61.1 4.9671 2   242 17.8    392.83\n",
       "4 33.4  0.03237  0 2.18  0    0.458 6.998 45.8 6.0622 3   222 18.7    394.63\n",
       "5 36.2  0.06905  0 2.18  0    0.458 7.147 54.2 6.0622 3   222 18.7    396.90\n",
       "6 28.7  0.02985  0 2.18  0    0.458 6.430 58.7 6.0622 3   222 18.7    394.12\n",
       "  LSTAT\n",
       "1 4.98 \n",
       "2 9.14 \n",
       "3 4.03 \n",
       "4 2.94 \n",
       "5 5.33 \n",
       "6 5.21 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boston = read.csv(\"boston_corrected.csv\", header = TRUE)\n",
    "boston = boston[, 7:20]\n",
    "head(boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we create a binary variable, `crim.med`, which is \"Yes\" if `CRIM` contains a value above the median and \"No\" otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>CMEDV</th><th scope=col>CRIM</th><th scope=col>ZN</th><th scope=col>INDUS</th><th scope=col>CHAS</th><th scope=col>NOX</th><th scope=col>RM</th><th scope=col>AGE</th><th scope=col>DIS</th><th scope=col>RAD</th><th scope=col>TAX</th><th scope=col>PTRATIO</th><th scope=col>B</th><th scope=col>LSTAT</th><th scope=col>crim.med</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>24.0   </td><td>0.00632</td><td>18     </td><td>2.31   </td><td>0      </td><td>0.538  </td><td>6.575  </td><td>65.2   </td><td>4.0900 </td><td>1      </td><td>296    </td><td>15.3   </td><td>396.90 </td><td>4.98   </td><td>No     </td></tr>\n",
       "\t<tr><td>21.6   </td><td>0.02731</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>6.421  </td><td>78.9   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>396.90 </td><td>9.14   </td><td>No     </td></tr>\n",
       "\t<tr><td>34.7   </td><td>0.02729</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>7.185  </td><td>61.1   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>392.83 </td><td>4.03   </td><td>No     </td></tr>\n",
       "\t<tr><td>33.4   </td><td>0.03237</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.998  </td><td>45.8   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.63 </td><td>2.94   </td><td>No     </td></tr>\n",
       "\t<tr><td>36.2   </td><td>0.06905</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>7.147  </td><td>54.2   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>396.90 </td><td>5.33   </td><td>No     </td></tr>\n",
       "\t<tr><td>28.7   </td><td>0.02985</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.430  </td><td>58.7   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.12 </td><td>5.21   </td><td>No     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " CMEDV & CRIM & ZN & INDUS & CHAS & NOX & RM & AGE & DIS & RAD & TAX & PTRATIO & B & LSTAT & crim.med\\\\\n",
       "\\hline\n",
       "\t 24.0    & 0.00632 & 18      & 2.31    & 0       & 0.538   & 6.575   & 65.2    & 4.0900  & 1       & 296     & 15.3    & 396.90  & 4.98    & No     \\\\\n",
       "\t 21.6    & 0.02731 &  0      & 7.07    & 0       & 0.469   & 6.421   & 78.9    & 4.9671  & 2       & 242     & 17.8    & 396.90  & 9.14    & No     \\\\\n",
       "\t 34.7    & 0.02729 &  0      & 7.07    & 0       & 0.469   & 7.185   & 61.1    & 4.9671  & 2       & 242     & 17.8    & 392.83  & 4.03    & No     \\\\\n",
       "\t 33.4    & 0.03237 &  0      & 2.18    & 0       & 0.458   & 6.998   & 45.8    & 6.0622  & 3       & 222     & 18.7    & 394.63  & 2.94    & No     \\\\\n",
       "\t 36.2    & 0.06905 &  0      & 2.18    & 0       & 0.458   & 7.147   & 54.2    & 6.0622  & 3       & 222     & 18.7    & 396.90  & 5.33    & No     \\\\\n",
       "\t 28.7    & 0.02985 &  0      & 2.18    & 0       & 0.458   & 6.430   & 58.7    & 6.0622  & 3       & 222     & 18.7    & 394.12  & 5.21    & No     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| CMEDV | CRIM | ZN | INDUS | CHAS | NOX | RM | AGE | DIS | RAD | TAX | PTRATIO | B | LSTAT | crim.med |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 24.0    | 0.00632 | 18      | 2.31    | 0       | 0.538   | 6.575   | 65.2    | 4.0900  | 1       | 296     | 15.3    | 396.90  | 4.98    | No      |\n",
       "| 21.6    | 0.02731 |  0      | 7.07    | 0       | 0.469   | 6.421   | 78.9    | 4.9671  | 2       | 242     | 17.8    | 396.90  | 9.14    | No      |\n",
       "| 34.7    | 0.02729 |  0      | 7.07    | 0       | 0.469   | 7.185   | 61.1    | 4.9671  | 2       | 242     | 17.8    | 392.83  | 4.03    | No      |\n",
       "| 33.4    | 0.03237 |  0      | 2.18    | 0       | 0.458   | 6.998   | 45.8    | 6.0622  | 3       | 222     | 18.7    | 394.63  | 2.94    | No      |\n",
       "| 36.2    | 0.06905 |  0      | 2.18    | 0       | 0.458   | 7.147   | 54.2    | 6.0622  | 3       | 222     | 18.7    | 396.90  | 5.33    | No      |\n",
       "| 28.7    | 0.02985 |  0      | 2.18    | 0       | 0.458   | 6.430   | 58.7    | 6.0622  | 3       | 222     | 18.7    | 394.12  | 5.21    | No      |\n",
       "\n"
      ],
      "text/plain": [
       "  CMEDV CRIM    ZN INDUS CHAS NOX   RM    AGE  DIS    RAD TAX PTRATIO B     \n",
       "1 24.0  0.00632 18 2.31  0    0.538 6.575 65.2 4.0900 1   296 15.3    396.90\n",
       "2 21.6  0.02731  0 7.07  0    0.469 6.421 78.9 4.9671 2   242 17.8    396.90\n",
       "3 34.7  0.02729  0 7.07  0    0.469 7.185 61.1 4.9671 2   242 17.8    392.83\n",
       "4 33.4  0.03237  0 2.18  0    0.458 6.998 45.8 6.0622 3   222 18.7    394.63\n",
       "5 36.2  0.06905  0 2.18  0    0.458 7.147 54.2 6.0622 3   222 18.7    396.90\n",
       "6 28.7  0.02985  0 2.18  0    0.458 6.430 58.7 6.0622 3   222 18.7    394.12\n",
       "  LSTAT crim.med\n",
       "1 4.98  No      \n",
       "2 9.14  No      \n",
       "3 4.03  No      \n",
       "4 2.94  No      \n",
       "5 5.33  No      \n",
       "6 5.21  No      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crim.med = rep(\"No\", dim(boston)[1])\n",
    "crim.med[boston$CRIM > median(boston$CRIM)] = \"Yes\"\n",
    "boston = data.frame(boston, crim.med)\n",
    "head(boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we explore the data both numerically, by looking at the matrix of correlations, and graphically, by looking at boxplots to investigate the association between `crim.med` and the other features. First, we look at the matrix of correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>CMEDV</dt>\n",
       "\t\t<dd>-0.389582440664448</dd>\n",
       "\t<dt>CRIM</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>ZN</dt>\n",
       "\t\t<dd>-0.200469219662547</dd>\n",
       "\t<dt>INDUS</dt>\n",
       "\t\t<dd>0.406583411406259</dd>\n",
       "\t<dt>CHAS</dt>\n",
       "\t\t<dd>-0.0558915822222415</dd>\n",
       "\t<dt>NOX</dt>\n",
       "\t\t<dd>0.420971711392456</dd>\n",
       "\t<dt>RM</dt>\n",
       "\t\t<dd>-0.219246702862514</dd>\n",
       "\t<dt>AGE</dt>\n",
       "\t\t<dd>0.352734250901364</dd>\n",
       "\t<dt>DIS</dt>\n",
       "\t\t<dd>-0.379670086951024</dd>\n",
       "\t<dt>RAD</dt>\n",
       "\t\t<dd>0.625505145262602</dd>\n",
       "\t<dt>TAX</dt>\n",
       "\t\t<dd>0.582764312032585</dd>\n",
       "\t<dt>PTRATIO</dt>\n",
       "\t\t<dd>0.28994557927952</dd>\n",
       "\t<dt>B</dt>\n",
       "\t\t<dd>-0.385063941994224</dd>\n",
       "\t<dt>LSTAT</dt>\n",
       "\t\t<dd>0.455621479447946</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[CMEDV] -0.389582440664448\n",
       "\\item[CRIM] 1\n",
       "\\item[ZN] -0.200469219662547\n",
       "\\item[INDUS] 0.406583411406259\n",
       "\\item[CHAS] -0.0558915822222415\n",
       "\\item[NOX] 0.420971711392456\n",
       "\\item[RM] -0.219246702862514\n",
       "\\item[AGE] 0.352734250901364\n",
       "\\item[DIS] -0.379670086951024\n",
       "\\item[RAD] 0.625505145262602\n",
       "\\item[TAX] 0.582764312032585\n",
       "\\item[PTRATIO] 0.28994557927952\n",
       "\\item[B] -0.385063941994224\n",
       "\\item[LSTAT] 0.455621479447946\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "CMEDV\n",
       ":   -0.389582440664448CRIM\n",
       ":   1ZN\n",
       ":   -0.200469219662547INDUS\n",
       ":   0.406583411406259CHAS\n",
       ":   -0.0558915822222415NOX\n",
       ":   0.420971711392456RM\n",
       ":   -0.219246702862514AGE\n",
       ":   0.352734250901364DIS\n",
       ":   -0.379670086951024RAD\n",
       ":   0.625505145262602TAX\n",
       ":   0.582764312032585PTRATIO\n",
       ":   0.28994557927952B\n",
       ":   -0.385063941994224LSTAT\n",
       ":   0.455621479447946\n",
       "\n"
      ],
      "text/plain": [
       "      CMEDV        CRIM          ZN       INDUS        CHAS         NOX \n",
       "-0.38958244  1.00000000 -0.20046922  0.40658341 -0.05589158  0.42097171 \n",
       "         RM         AGE         DIS         RAD         TAX     PTRATIO \n",
       "-0.21924670  0.35273425 -0.37967009  0.62550515  0.58276431  0.28994558 \n",
       "          B       LSTAT \n",
       "-0.38506394  0.45562148 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor(boston[, -15])[, \"CRIM\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are some moderate to moderately strong correlations between crime rate and the other variables. The most correlated variables are `RAD` (correlation of 0.626), a measure of accessibility to radial highways, and `TAX` (correlation of 0.583), the property tax rate in USD per \\$10,000. In fact, all of the variables aside from `CHAS`, an indicator variable with value 1 if a town borders the Charles River, have correlation values with a magnitude of at least 0.2. In addition, as we saw in Applied Exercise 8 from Chapter 3, every predictor aside from `CHAS` had a statistically significant association with `CRIM` when we performed univariate linear regressions. While we should first explore the data graphically, there are two possible subsets of predictors that immeidately jump out as candidates for use in producing models to predict whether or not a given suburb has a per capita crime rate above the median. First would be to use all of the predictors aside from `CHAS` and second would be to use the predictors with a correlation magnitude of at least 0.3 (`CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`). We will make models using both subsets of predictors to compare the predictive strength of the various models. Before making further choices regarding which predictors to use when fitting models, we will look at boxplots to explore the data graphically. We start with boxplots of each predictor, aside from `CHAS`, comparing the suburbs with above-median crime rate and those with below-median crime rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nkQAEIBKAAEQCEIBIAAL+B7mwz69AbFe7AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "par(mfrow = c(2, 3))\n",
    "plot(boston$crim.med, boston$CMEDV, ylab = \"Median home value ($1000)\")\n",
    "plot(boston$crim.med, boston$ZN, ylab = \"Proportion of land zoned for 25000+ sq ft lots\")\n",
    "plot(boston$crim.med, boston$INDUS, ylab = \"Proportion of non-retail business acres\")\n",
    "plot(boston$crim.med, boston$NOX, ylab = \"Nitric oxides concentration (parts per 10 million)\")\n",
    "plot(boston$crim.med, boston$RM, ylab = \"Average rooms per home\")\n",
    "plot(boston$crim.med, boston$AGE, ylab = \"Proportion of homes built before 1940\")\n",
    "mtext(\"Boxplots for towns with above (Yes) and below (No) median crime rate\", outer = TRUE, line = -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "par(mfrow = c(2, 3))\n",
    "plot(boston$crim.med, boston$DIS, ylab = \"Weighted distance to Boston employment centers\")\n",
    "plot(boston$crim.med, boston$RAD, ylab = \"Index of accessibility to radial highways\")\n",
    "plot(boston$crim.med, boston$TAX, ylab = \"Property tax rate (USD per $10000)\")\n",
    "plot(boston$crim.med, boston$PTRATIO, ylab = \"Pupil-teacher ratio\")\n",
    "plot(boston$crim.med, boston$B, ylab = \"1000*(Proportion of black residents - 0.63)^2\")\n",
    "plot(boston$crim.med, boston$LSTAT, ylab = \"Proportion lower socioeconomic status population\")\n",
    "mtext(\"Boxplots for towns with above (Yes) and below (No) median crime rate\", outer = TRUE, line = -3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twelve boxplots we produced provide further evidence to suggest that the predictors which are likely to be most useful in predicting `crim.med` are those having a correlation magnitude of at least 0.3 with `CRIM` (`CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`). Those are the variables which show the most separation in distributions between the suburbs with above-median crime rates and those with below-median crime rates. In particular, for all of those variables except `CMEDV`, it appears that the medians for the suburbs with above-median crime rates are well clear of the upper or lower quartile (depending on the particular variable) of the values for suburbs with below-median crime rates. Therefore, we will proceed and produce models using two different subsets of predictors: all of them aside from `CHAS`, and only the ones which are at least moderately correlated with `CRIM` (`CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`).\n",
    "\n",
    "Before training any models, we split our data in to a training set and a test set using the 75%-25% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(312)\n",
    "train = sample(dim(boston)[1], size = 0.75*dim(Boston)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split the data in to a training set and a test set, we fit classification models to predict whether or not a given suburb has an above-median crime rate. Note that for this exercise we will stick with the default prediction threshold of 50% for convenience. If we were trying to make predictions for an application, then we should consider other prediction thresholds depending on our tolerance for false positives versus false negatives. Here we use the convention that an above-median crime rate is the positive category and below-median the negative category. For each model, we will first use all of the predictors before using the ones which are at least moderately correlated with `CRIM`. The first classification model we use is logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted No Yes\n",
       "      No  57   3\n",
       "      Yes  5  62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(crim.med ~ . - CRIM - CHAS, data = boston, subset = train, family = \"binomial\")\n",
    "glm.probs = predict(glm.fit, boston[-train, ], type = \"response\")\n",
    "glm.pred = rep(\"No\", dim(boston[-train, ])[1])\n",
    "glm.pred[glm.probs > 0.5] = \"Yes\"\n",
    "table(glm.pred, boston[-train, \"crim.med\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.062992125984252"
      ],
      "text/latex": [
       "0.062992125984252"
      ],
      "text/markdown": [
       "0.062992125984252"
      ],
      "text/plain": [
       "[1] 0.06299213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(glm.pred == boston[-train, \"crim.med\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using logistic regression to predict `crim.med` using all of the predictors aside from `CHAS`, we had an overall test error of 6.3%. Our positive predictive value was $62/67 \\approx 0.925$ and our true positive rate was $62/65 \\approx 0.954$. So far that seems like a pretty good error rate for the first model we tried, so lets continue with the smaller subset of predictors and then move on to other models to see if we can improve the performance at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted No Yes\n",
       "      No  58   8\n",
       "      Yes  4  57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(crim.med ~ CMEDV + INDUS + NOX + AGE + DIS + RAD + TAX + B + LSTAT,\n",
    "             data = boston, subset = train, family = \"binomial\")\n",
    "glm.probs = predict(glm.fit, boston[-train, ], type = \"response\")\n",
    "glm.pred = rep(\"No\", dim(boston[-train, ])[1])\n",
    "glm.pred[glm.probs > 0.5] = \"Yes\"\n",
    "table(glm.pred, boston[-train, \"crim.med\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.094488188976378"
      ],
      "text/latex": [
       "0.094488188976378"
      ],
      "text/markdown": [
       "0.094488188976378"
      ],
      "text/plain": [
       "[1] 0.09448819"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(glm.pred == boston[-train, \"crim.med\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model using fewer predictors (`CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`) performed slightly worse, with an overall test error of 9.4%. It had a positive predictive value of $57/61 \\approx 0.934$, which is a slight improvement over the model with more predictors. However, the true positive rate is also a little worse, at $57/65 \\approx 0.877$. This is due to the fact that source of error for the model with fewer predictors is mis-classifying suburbs which actually have above-median crime rates as being in the below-median category. We now move on to linear discriminant analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted No Yes\n",
       "      No  56  17\n",
       "      Yes  6  48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda.fit = lda(crim.med ~ . - CRIM - CHAS, data = boston, subset = train)\n",
    "lda.pred = predict(lda.fit, boston[-train, ])\n",
    "table(lda.pred$class, boston[-train, \"crim.med\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.181102362204724"
      ],
      "text/latex": [
       "0.181102362204724"
      ],
      "text/markdown": [
       "0.181102362204724"
      ],
      "text/plain": [
       "[1] 0.1811024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(lda.pred$class == boston[-train, \"crim.med\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the logistic regression model using all of the predictors aside from `CHAS`, linear discriminant analysis performed much worse, with an overal test error of 18.1%. That is almost triple the overall test error from logistic regression. This performance discrepancy suggests that the assumption underlying LDA, that the observations are drawn from a Gaussian distribution where both classes share a common covariance matrix, are not met for at least some of these predictors. Once again, the source of the error comes from mis-classifying suburbs which actuall have above-median crime rates as being in the below-median category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted No Yes\n",
       "      No  59  16\n",
       "      Yes  3  49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda.fit = lda(crim.med ~ CMEDV + INDUS + NOX + AGE + DIS + RAD + TAX + B + LSTAT, data = boston, subset = train)\n",
    "lda.pred = predict(lda.fit, boston[-train, ])\n",
    "table(lda.pred$class, boston[-train, \"crim.med\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.149606299212598"
      ],
      "text/latex": [
       "0.149606299212598"
      ],
      "text/markdown": [
       "0.149606299212598"
      ],
      "text/plain": [
       "[1] 0.1496063"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(lda.pred$class == boston[-train, \"crim.med\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the model which used all of the predictors aside from `CHAS`, linear discriminant analysis using fewer predictors (`CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`) performed worse than the logistic regression model using the same predictors. It did, however, perform a bit better than the LDA model which used more predictors. The improvement between LDA models comes mainly from improving the false positive rate. So far logistic regression appears to give the best test error rate. We continue on to quadratic discriminant analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted No Yes\n",
       "      No  61  12\n",
       "      Yes  1  53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.fit = qda(crim.med ~ . - CRIM - CHAS, data = boston, subset = train)\n",
    "qda.pred = predict(qda.fit, boston[-train, ])\n",
    "table(qda.pred$class, boston[-train, \"crim.med\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.102362204724409"
      ],
      "text/latex": [
       "0.102362204724409"
      ],
      "text/markdown": [
       "0.102362204724409"
      ],
      "text/plain": [
       "[1] 0.1023622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(qda.pred$class == boston[-train, \"crim.med\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic discriminant analysis with all of the predictors aside from `CHAS` had an overall test error of 10.2%, which is comparable to that of logistic regression using the predictors `CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`. This is a solid improvement over linear discriminant analysis using the same predictors, and suggests that relaxing the assuption of a common covariance matrix for both classes to assuming each class has its own covariance matrix is a more accurate assumption about the data. One thing of note is that the QDA model has a high positive predictive value of $53/54 \\approx 0.981$, which is highest value out of all of the models we have seen up to this point. This model would be very good if our priority is to minimize the number of suburbs with below-median crime rates that are predicted to be in the above-median category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted No Yes\n",
       "      No  59  13\n",
       "      Yes  3  52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qda.fit = qda(crim.med ~ CMEDV + INDUS + NOX + AGE + DIS + RAD + TAX + B + LSTAT, data = boston, subset = train)\n",
    "qda.pred = predict(qda.fit, boston[-train, ])\n",
    "table(qda.pred$class, boston[-train, \"crim.med\"], dnn = c(\"Predicted\", \"Actual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.125984251968504"
      ],
      "text/latex": [
       "0.125984251968504"
      ],
      "text/markdown": [
       "0.125984251968504"
      ],
      "text/plain": [
       "[1] 0.1259843"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(qda.pred$class == boston[-train, \"crim.med\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing to the smaller subset of predictors (`CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`) resulted in a QDA model that performs slightly worse in terms of overall test error rate (12.6%) than the QDA model with more predictors. Even so, this QDA model still has a better overall test error rate than both of the LDA models.\n",
    "\n",
    "Before moving on to $k$-nearest neighbors classification, we make sure to standardize all of the variables to have mean zero and standard deviation one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>CMEDV</th><th scope=col>ZN</th><th scope=col>INDUS</th><th scope=col>NOX</th><th scope=col>RM</th><th scope=col>AGE</th><th scope=col>DIS</th><th scope=col>RAD</th><th scope=col>TAX</th><th scope=col>PTRATIO</th><th scope=col>B</th><th scope=col>LSTAT</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0.1602176</td><td> 0.2845483</td><td>-1.2866362</td><td>-0.1440749</td><td>0.4132629 </td><td>-0.1198948</td><td>0.140075  </td><td>-0.9818712</td><td>-0.6659492</td><td>-1.4575580</td><td>0.4406159 </td><td>-1.0744990</td></tr>\n",
       "\t<tr><td>-0.1011583</td><td>-0.4872402</td><td>-0.5927944</td><td>-0.7395304</td><td>0.1940824 </td><td> 0.3668034</td><td>0.556609  </td><td>-0.8670245</td><td>-0.9863534</td><td>-0.3027945</td><td>0.4406159 </td><td>-0.4919525</td></tr>\n",
       "\t<tr><td> 1.3255187</td><td>-0.4872402</td><td>-0.5927944</td><td>-0.7395304</td><td>1.2814456 </td><td>-0.2655490</td><td>0.556609  </td><td>-0.8670245</td><td>-0.9863534</td><td>-0.3027945</td><td>0.3960351 </td><td>-1.2075324</td></tr>\n",
       "\t<tr><td> 1.1839401</td><td>-0.4872402</td><td>-1.3055857</td><td>-0.8344581</td><td>1.0152978 </td><td>-0.8090878</td><td>1.076671  </td><td>-0.7521778</td><td>-1.1050216</td><td> 0.1129203</td><td>0.4157514 </td><td>-1.3601708</td></tr>\n",
       "\t<tr><td> 1.4888787</td><td>-0.4872402</td><td>-1.3055857</td><td>-0.8344581</td><td>1.2273620 </td><td>-0.5106743</td><td>1.076671  </td><td>-0.7521778</td><td>-1.1050216</td><td> 0.1129203</td><td>0.4406159 </td><td>-1.0254866</td></tr>\n",
       "\t<tr><td> 0.6720789</td><td>-0.4872402</td><td>-1.3055857</td><td>-0.8344581</td><td>0.2068916 </td><td>-0.3508100</td><td>1.076671  </td><td>-0.7521778</td><td>-1.1050216</td><td> 0.1129203</td><td>0.4101651 </td><td>-1.0422909</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllll}\n",
       " CMEDV & ZN & INDUS & NOX & RM & AGE & DIS & RAD & TAX & PTRATIO & B & LSTAT\\\\\n",
       "\\hline\n",
       "\t  0.1602176 &  0.2845483 & -1.2866362 & -0.1440749 & 0.4132629  & -0.1198948 & 0.140075   & -0.9818712 & -0.6659492 & -1.4575580 & 0.4406159  & -1.0744990\\\\\n",
       "\t -0.1011583 & -0.4872402 & -0.5927944 & -0.7395304 & 0.1940824  &  0.3668034 & 0.556609   & -0.8670245 & -0.9863534 & -0.3027945 & 0.4406159  & -0.4919525\\\\\n",
       "\t  1.3255187 & -0.4872402 & -0.5927944 & -0.7395304 & 1.2814456  & -0.2655490 & 0.556609   & -0.8670245 & -0.9863534 & -0.3027945 & 0.3960351  & -1.2075324\\\\\n",
       "\t  1.1839401 & -0.4872402 & -1.3055857 & -0.8344581 & 1.0152978  & -0.8090878 & 1.076671   & -0.7521778 & -1.1050216 &  0.1129203 & 0.4157514  & -1.3601708\\\\\n",
       "\t  1.4888787 & -0.4872402 & -1.3055857 & -0.8344581 & 1.2273620  & -0.5106743 & 1.076671   & -0.7521778 & -1.1050216 &  0.1129203 & 0.4406159  & -1.0254866\\\\\n",
       "\t  0.6720789 & -0.4872402 & -1.3055857 & -0.8344581 & 0.2068916  & -0.3508100 & 1.076671   & -0.7521778 & -1.1050216 &  0.1129203 & 0.4101651  & -1.0422909\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| CMEDV | ZN | INDUS | NOX | RM | AGE | DIS | RAD | TAX | PTRATIO | B | LSTAT |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  0.1602176 |  0.2845483 | -1.2866362 | -0.1440749 | 0.4132629  | -0.1198948 | 0.140075   | -0.9818712 | -0.6659492 | -1.4575580 | 0.4406159  | -1.0744990 |\n",
       "| -0.1011583 | -0.4872402 | -0.5927944 | -0.7395304 | 0.1940824  |  0.3668034 | 0.556609   | -0.8670245 | -0.9863534 | -0.3027945 | 0.4406159  | -0.4919525 |\n",
       "|  1.3255187 | -0.4872402 | -0.5927944 | -0.7395304 | 1.2814456  | -0.2655490 | 0.556609   | -0.8670245 | -0.9863534 | -0.3027945 | 0.3960351  | -1.2075324 |\n",
       "|  1.1839401 | -0.4872402 | -1.3055857 | -0.8344581 | 1.0152978  | -0.8090878 | 1.076671   | -0.7521778 | -1.1050216 |  0.1129203 | 0.4157514  | -1.3601708 |\n",
       "|  1.4888787 | -0.4872402 | -1.3055857 | -0.8344581 | 1.2273620  | -0.5106743 | 1.076671   | -0.7521778 | -1.1050216 |  0.1129203 | 0.4406159  | -1.0254866 |\n",
       "|  0.6720789 | -0.4872402 | -1.3055857 | -0.8344581 | 0.2068916  | -0.3508100 | 1.076671   | -0.7521778 | -1.1050216 |  0.1129203 | 0.4101651  | -1.0422909 |\n",
       "\n"
      ],
      "text/plain": [
       "     CMEDV      ZN         INDUS      NOX        RM        AGE        DIS     \n",
       "[1,]  0.1602176  0.2845483 -1.2866362 -0.1440749 0.4132629 -0.1198948 0.140075\n",
       "[2,] -0.1011583 -0.4872402 -0.5927944 -0.7395304 0.1940824  0.3668034 0.556609\n",
       "[3,]  1.3255187 -0.4872402 -0.5927944 -0.7395304 1.2814456 -0.2655490 0.556609\n",
       "[4,]  1.1839401 -0.4872402 -1.3055857 -0.8344581 1.0152978 -0.8090878 1.076671\n",
       "[5,]  1.4888787 -0.4872402 -1.3055857 -0.8344581 1.2273620 -0.5106743 1.076671\n",
       "[6,]  0.6720789 -0.4872402 -1.3055857 -0.8344581 0.2068916 -0.3508100 1.076671\n",
       "     RAD        TAX        PTRATIO    B         LSTAT     \n",
       "[1,] -0.9818712 -0.6659492 -1.4575580 0.4406159 -1.0744990\n",
       "[2,] -0.8670245 -0.9863534 -0.3027945 0.4406159 -0.4919525\n",
       "[3,] -0.8670245 -0.9863534 -0.3027945 0.3960351 -1.2075324\n",
       "[4,] -0.7521778 -1.1050216  0.1129203 0.4157514 -1.3601708\n",
       "[5,] -0.7521778 -1.1050216  0.1129203 0.4406159 -1.0254866\n",
       "[6,] -0.7521778 -1.1050216  0.1129203 0.4101651 -1.0422909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled.boston = scale(boston[, -c(2, 5, 15)])\n",
    "head(scaled.boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.X = scaled.boston[train, ]\n",
    "test.X = scaled.boston[-train, ]\n",
    "train.crim.med = boston[train, \"crim.med\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>k.vals</th><th scope=col>knn.error</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1        </td><td>0.10236220</td></tr>\n",
       "\t<tr><td> 3        </td><td>0.07086614</td></tr>\n",
       "\t<tr><td> 5        </td><td>0.08661417</td></tr>\n",
       "\t<tr><td> 7        </td><td>0.10236220</td></tr>\n",
       "\t<tr><td> 9        </td><td>0.11811024</td></tr>\n",
       "\t<tr><td>11        </td><td>0.13385827</td></tr>\n",
       "\t<tr><td>13        </td><td>0.11023622</td></tr>\n",
       "\t<tr><td>15        </td><td>0.11811024</td></tr>\n",
       "\t<tr><td>17        </td><td>0.13385827</td></tr>\n",
       "\t<tr><td>19        </td><td>0.13385827</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " k.vals & knn.error\\\\\n",
       "\\hline\n",
       "\t  1         & 0.10236220\\\\\n",
       "\t  3         & 0.07086614\\\\\n",
       "\t  5         & 0.08661417\\\\\n",
       "\t  7         & 0.10236220\\\\\n",
       "\t  9         & 0.11811024\\\\\n",
       "\t 11         & 0.13385827\\\\\n",
       "\t 13         & 0.11023622\\\\\n",
       "\t 15         & 0.11811024\\\\\n",
       "\t 17         & 0.13385827\\\\\n",
       "\t 19         & 0.13385827\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| k.vals | knn.error |\n",
       "|---|---|\n",
       "|  1         | 0.10236220 |\n",
       "|  3         | 0.07086614 |\n",
       "|  5         | 0.08661417 |\n",
       "|  7         | 0.10236220 |\n",
       "|  9         | 0.11811024 |\n",
       "| 11         | 0.13385827 |\n",
       "| 13         | 0.11023622 |\n",
       "| 15         | 0.11811024 |\n",
       "| 17         | 0.13385827 |\n",
       "| 19         | 0.13385827 |\n",
       "\n"
      ],
      "text/plain": [
       "      k.vals knn.error \n",
       " [1,]  1     0.10236220\n",
       " [2,]  3     0.07086614\n",
       " [3,]  5     0.08661417\n",
       " [4,]  7     0.10236220\n",
       " [5,]  9     0.11811024\n",
       " [6,] 11     0.13385827\n",
       " [7,] 13     0.11023622\n",
       " [8,] 15     0.11811024\n",
       " [9,] 17     0.13385827\n",
       "[10,] 19     0.13385827"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(312)\n",
    "k.vals = (1:10)*2 - 1\n",
    "knn.error = rep(0, 10)\n",
    "knn.tables = list()\n",
    "for (i in 1:10){\n",
    "    knn.pred = knn(train.X, test.X, train.crim.med, k = 2*i - 1)\n",
    "    knn.tables[[k.vals[i]]] = table(knn.pred, boston[-train, \"crim.med\"], dnn = c(\"Predicted\", \"Actual\"))\n",
    "    knn.error[i] = 1 - mean(knn.pred == boston[-train, \"crim.med\"])\n",
    "}\n",
    "cbind(k.vals, knn.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted No Yes\n",
       "      No  61   8\n",
       "      Yes  1  57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn.tables[[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when using all of the predictors aside from `CHAS`, the value of $k$ with the lowest overall test error for $k$-nearest neighbors classification is $k = 3$, with an overal test error of 7.1%. This is just one additional mis-classified test observation compared to logistic regression using the same predictors. Looking at the confusion matrix, we see that KNN with $k = 3$ has the best positive predictive value out of all of the classification models, $57/58 \\approx 0.983$, though compared to logistic regression using the same predictors, this model has a worse true positive rate ($57/65 \\approx 0.877$ vs 0.954)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = c(\"CMEDV\", \"INDUS\", \"NOX\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"B\", \"LSTAT\")\n",
    "train.X = scaled.boston[train, cols]\n",
    "test.X = scaled.boston[-train, cols]\n",
    "train.crim.med = boston[train, \"crim.med\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>k.vals</th><th scope=col>knn.error</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1        </td><td>0.08661417</td></tr>\n",
       "\t<tr><td> 3        </td><td>0.07086614</td></tr>\n",
       "\t<tr><td> 5        </td><td>0.08661417</td></tr>\n",
       "\t<tr><td> 7        </td><td>0.09448819</td></tr>\n",
       "\t<tr><td> 9        </td><td>0.11811024</td></tr>\n",
       "\t<tr><td>11        </td><td>0.14173228</td></tr>\n",
       "\t<tr><td>13        </td><td>0.12598425</td></tr>\n",
       "\t<tr><td>15        </td><td>0.14173228</td></tr>\n",
       "\t<tr><td>17        </td><td>0.14173228</td></tr>\n",
       "\t<tr><td>19        </td><td>0.13385827</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " k.vals & knn.error\\\\\n",
       "\\hline\n",
       "\t  1         & 0.08661417\\\\\n",
       "\t  3         & 0.07086614\\\\\n",
       "\t  5         & 0.08661417\\\\\n",
       "\t  7         & 0.09448819\\\\\n",
       "\t  9         & 0.11811024\\\\\n",
       "\t 11         & 0.14173228\\\\\n",
       "\t 13         & 0.12598425\\\\\n",
       "\t 15         & 0.14173228\\\\\n",
       "\t 17         & 0.14173228\\\\\n",
       "\t 19         & 0.13385827\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| k.vals | knn.error |\n",
       "|---|---|\n",
       "|  1         | 0.08661417 |\n",
       "|  3         | 0.07086614 |\n",
       "|  5         | 0.08661417 |\n",
       "|  7         | 0.09448819 |\n",
       "|  9         | 0.11811024 |\n",
       "| 11         | 0.14173228 |\n",
       "| 13         | 0.12598425 |\n",
       "| 15         | 0.14173228 |\n",
       "| 17         | 0.14173228 |\n",
       "| 19         | 0.13385827 |\n",
       "\n"
      ],
      "text/plain": [
       "      k.vals knn.error \n",
       " [1,]  1     0.08661417\n",
       " [2,]  3     0.07086614\n",
       " [3,]  5     0.08661417\n",
       " [4,]  7     0.09448819\n",
       " [5,]  9     0.11811024\n",
       " [6,] 11     0.14173228\n",
       " [7,] 13     0.12598425\n",
       " [8,] 15     0.14173228\n",
       " [9,] 17     0.14173228\n",
       "[10,] 19     0.13385827"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(312)\n",
    "k.vals = (1:10)*2 - 1\n",
    "knn.error = rep(0, 10)\n",
    "knn.tables = list()\n",
    "for (i in 1:10){\n",
    "    knn.pred = knn(train.X, test.X, train.crim.med, k = 2*i - 1)\n",
    "    knn.tables[[k.vals[i]]] = table(knn.pred, boston[-train, \"crim.med\"], dnn = c(\"Predicted\", \"Actual\"))\n",
    "    knn.error[i] = 1 - mean(knn.pred == boston[-train, \"crim.med\"])\n",
    "}\n",
    "cbind(k.vals, knn.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Actual\n",
       "Predicted No Yes\n",
       "      No  61   8\n",
       "      Yes  1  57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn.tables[[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing to the smaller subset of predictors (`CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`), we see that again the value of $k$ with the lowest overall test error rate is $k = 3$. In fact, KNN with $k = 3$ and this subset of predictors has the same confusion matrix as the previous KNN classifier which used more predictors. \n",
    "\n",
    "While we would need more precisely determine the metrics by which we would choose our preferred model and then perform further testing, such as cross validation, to more confidently choose a model, it seems as if there are two likely frontrunners to choose: logistic regression using all of the predictors aside from `CHAS`, and $k$-nearest neighbors using $k = 3$ and the smaller subset predictors (`CMEDV`, `INDUS`, `NOX`, `AGE`, `DIS`, `RAD`, `TAX`, `B`, and `LSTAT`). The strength of the logistic regression model lies in relative simplicity and interpretability compared to KNN, as well as the fact that it had the lowest overall test error out of the models we explored. The KNN classifier had comparable overall test error, but had a much better positive predictive value than logistic regression, at least when logistic regression used a prediction threshold of 0.5. One graphic we could use to better compare the performance of these two models would be to produce ROC curves for each model and compare the two area-under-curve values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
