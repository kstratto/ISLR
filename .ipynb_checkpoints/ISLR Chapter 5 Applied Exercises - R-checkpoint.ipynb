{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 1\n",
    "\n",
    "**In Chapter 4, we used logistic regression to predict the probability of `default` using `income` and `balance` on the `Default` data set. We will now estimate the test error of this logistic regression model using te validation set approach. Do not forget to set a random seed before beginning your analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>default</th><th scope=col>student</th><th scope=col>balance</th><th scope=col>income</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>No       </td><td>No       </td><td> 729.5265</td><td>44361.625</td></tr>\n",
       "\t<tr><td>No       </td><td>Yes      </td><td> 817.1804</td><td>12106.135</td></tr>\n",
       "\t<tr><td>No       </td><td>No       </td><td>1073.5492</td><td>31767.139</td></tr>\n",
       "\t<tr><td>No       </td><td>No       </td><td> 529.2506</td><td>35704.494</td></tr>\n",
       "\t<tr><td>No       </td><td>No       </td><td> 785.6559</td><td>38463.496</td></tr>\n",
       "\t<tr><td>No       </td><td>Yes      </td><td> 919.5885</td><td> 7491.559</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " default & student & balance & income\\\\\n",
       "\\hline\n",
       "\t No        & No        &  729.5265 & 44361.625\\\\\n",
       "\t No        & Yes       &  817.1804 & 12106.135\\\\\n",
       "\t No        & No        & 1073.5492 & 31767.139\\\\\n",
       "\t No        & No        &  529.2506 & 35704.494\\\\\n",
       "\t No        & No        &  785.6559 & 38463.496\\\\\n",
       "\t No        & Yes       &  919.5885 &  7491.559\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| default | student | balance | income |\n",
       "|---|---|---|---|\n",
       "| No        | No        |  729.5265 | 44361.625 |\n",
       "| No        | Yes       |  817.1804 | 12106.135 |\n",
       "| No        | No        | 1073.5492 | 31767.139 |\n",
       "| No        | No        |  529.2506 | 35704.494 |\n",
       "| No        | No        |  785.6559 | 38463.496 |\n",
       "| No        | Yes       |  919.5885 |  7491.559 |\n",
       "\n"
      ],
      "text/plain": [
       "  default student balance   income   \n",
       "1 No      No       729.5265 44361.625\n",
       "2 No      Yes      817.1804 12106.135\n",
       "3 No      No      1073.5492 31767.139\n",
       "4 No      No       529.2506 35704.494\n",
       "5 No      No       785.6559 38463.496\n",
       "6 No      Yes      919.5885  7491.559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(312)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "**Fit a logistic regression model that uses `income` and `balance` to predict `default`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, we use the entire data set to fit a logisic regression model to predict `default` by using `income` and `balance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = \"binomial\", \n",
       "    data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4725  -0.1444  -0.0574  -0.0211   3.7245  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.154e+01  4.348e-01 -26.545  < 2e-16 ***\n",
       "income       2.081e-05  4.985e-06   4.174 2.99e-05 ***\n",
       "balance      5.647e-03  2.274e-04  24.836  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1579.0  on 9997  degrees of freedom\n",
       "AIC: 1585\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(default ~ income + balance, data = Default, family = \"binomial\")\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "**Using the validation set approach, estimate the test error of this model. In order to do this, youmust perform the following steps:**\n",
    "\n",
    "1. **Split the sample into a training set and a validation set.**\n",
    "2. **Fit a multiple logistic regression model using only the training observations.**\n",
    "3. **Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the `default` category if the posterior probability is greater than 0.5.**\n",
    "4. **Compute the validation set error, which is the fraction of observations in the validation set that are misclassified.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use a 75-25 split when dividing my data into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sample(dim(Default)[1], 0.75*dim(Default)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0284"
      ],
      "text/latex": [
       "0.0284"
      ],
      "text/markdown": [
       "0.0284"
      ],
      "text/plain": [
       "[1] 0.0284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(default ~ income + balance, data = Default, subset = train, family = \"binomial\")\n",
    "glm.probs = predict(glm.fit, Default[-train, ], type = \"response\")\n",
    "glm.preds = rep(\"No\", dim(Default)[1])\n",
    "glm.preds[glm.probs > 0.5] = \"Yes\"\n",
    "mean(glm.preds != Default[-train, \"default\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this train-test split, we had a validation set error of 0.0284, or 2.84% of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "**Repeat the process in Part 2 three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0268"
      ],
      "text/latex": [
       "0.0268"
      ],
      "text/markdown": [
       "0.0268"
      ],
      "text/plain": [
       "[1] 0.0268"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = sample(dim(Default)[1], 0.75*dim(Default)[1])\n",
    "glm.fit = glm(default ~ income + balance, data = Default, subset = train, family = \"binomial\")\n",
    "glm.probs = predict(glm.fit, Default[-train, ], type = \"response\")\n",
    "glm.preds = rep(\"No\", dim(Default)[1])\n",
    "glm.preds[glm.probs > 0.5] = \"Yes\"\n",
    "mean(glm.preds != Default[-train, \"default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0256"
      ],
      "text/latex": [
       "0.0256"
      ],
      "text/markdown": [
       "0.0256"
      ],
      "text/plain": [
       "[1] 0.0256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = sample(dim(Default)[1], 0.75*dim(Default)[1])\n",
    "glm.fit = glm(default ~ income + balance, data = Default, subset = train, family = \"binomial\")\n",
    "glm.probs = predict(glm.fit, Default[-train, ], type = \"response\")\n",
    "glm.preds = rep(\"No\", dim(Default)[1])\n",
    "glm.preds[glm.probs > 0.5] = \"Yes\"\n",
    "mean(glm.preds != Default[-train, \"default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0252"
      ],
      "text/latex": [
       "0.0252"
      ],
      "text/markdown": [
       "0.0252"
      ],
      "text/plain": [
       "[1] 0.0252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = sample(dim(Default)[1], 0.75*dim(Default)[1])\n",
    "glm.fit = glm(default ~ income + balance, data = Default, subset = train, family = \"binomial\")\n",
    "glm.probs = predict(glm.fit, Default[-train, ], type = \"response\")\n",
    "glm.preds = rep(\"No\", dim(Default)[1])\n",
    "glm.preds[glm.probs > 0.5] = \"Yes\"\n",
    "mean(glm.preds != Default[-train, \"default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0356"
      ],
      "text/latex": [
       "0.0356"
      ],
      "text/markdown": [
       "0.0356"
      ],
      "text/plain": [
       "[1] 0.0356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - mean(Default[-train, \"default\"] == \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using three different 75-25 splits of the data, our validation set error remained fairly consistent. The average error between this part and Part 2 was 0.0265, and errors were all within about 13% of each other. We also note that these test errors are all about 30% less than the test error one would have using the naive strategy of just saying that nobody will default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "**Now consider a logistic regression model that predicts the probability of `default` using `income`, `balance`, and a dummy variable for `student`. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for `student` leads to a reduction in the test error rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.000296"
      ],
      "text/latex": [
       "0.000296"
      ],
      "text/markdown": [
       "0.000296"
      ],
      "text/plain": [
       "[1] 0.000296"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with.student = rep(0, 50)\n",
    "without.student = rep(0, 50)\n",
    "for (i in 1:50){\n",
    "    train = sample(dim(Default)[1], 0.75*dim(Default)[1])\n",
    "    with.student.fit = glm(default ~ ., data = Default, subset = train, family = \"binomial\")\n",
    "    without.student.fit = glm(default ~ income + balance, data = Default, subset = train, family = \"binomial\")\n",
    "    with.student.probs = predict(with.student.fit, Default[-train, ], type = \"response\")\n",
    "    without.student.probs = predict(without.student.fit, Default[-train, ], type = \"response\")\n",
    "    with.student.preds = rep(\"No\", dim(Default)[1])\n",
    "    without.student.preds = rep(\"No\", dim(Default)[1])\n",
    "    with.student.preds[with.student.probs > 0.5] = \"Yes\"\n",
    "    without.student.preds[without.student.probs > 0.5] = \"Yes\"\n",
    "    with.student[i] = mean(with.student.preds != Default[-train, \"default\"])\n",
    "    without.student[i] = mean(without.student.preds != Default[-train, \"default\"])\n",
    "}\n",
    "difference = with.student - without.student\n",
    "errors = data.frame(with.student, without.student, difference)\n",
    "mean(errors$difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through 50 train-test splits and comparing the error rates between the logistic regression model predicting `default` using `income`, `balance`, and `student` and the logistic regression model predicting `default` using just `income` and `balance` for each split, we see that, on average, including a dummy variable for `student` does not lead to a reduction in the test error rate. In fact, on average it resulted in a very slight increase in the test error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 2\n",
    "\n",
    "**We continue to consider the use of a logistic regression model to predict the probability of `default` using `income` and `balance` on the `Default` data set. In particular, we will now compute estimates for the standard errors of the `income` and `balance` logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the `glm()` function. Do not forget to set a random seed before beginning your analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(312)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "**Using the `summary()` and `glm()` functions, determine the estimated standard errors for the coefficients associated with `income` and `balance` in a multiple logistic regression model that uses both predictors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = \"binomial\", \n",
       "    data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4725  -0.1444  -0.0574  -0.0211   3.7245  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.154e+01  4.348e-01 -26.545  < 2e-16 ***\n",
       "income       2.081e-05  4.985e-06   4.174 2.99e-05 ***\n",
       "balance      5.647e-03  2.274e-04  24.836  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1579.0  on 9997  degrees of freedom\n",
       "AIC: 1585\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(default ~ income + balance, data = Default, family = \"binomial\")\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `summary()` and `glm()` functions, the estimated standard error for the estimated coefficient of `income` is $4.985 \\times 10^{-6}$, while the estimated standard error for the estimated coefficient of `balance` is $2.274 \\times 10^{-4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "**Write a function, `boot.fn()` that takes as input the `Default` data as well as an index of the observations, and that outputs the coefficient estimates for `income` and `balance` in the multiple logistic regression model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.fn = function(data, index){\n",
    "    coefs = coef(glm(default ~ income + balance, data = data, subset = index, \n",
    "                     family = \"binomial\"))[c(\"income\", \"balance\")]\n",
    "    return(coefs)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "**Use the `boot()` fuction together with your `boot.fn()` function to estimate the standard errors of the logistic regression coefficients for `income` and `balance`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Default, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "        original       bias     std. error\n",
       "t1* 2.080898e-05 1.947180e-08 4.668888e-06\n",
       "t2* 5.647103e-03 1.362778e-05 2.323593e-04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Default, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bootstrap, the estimated standard errors of the logistic regression coefficients for `income` and `balance` are $4.669 \\times 10^{-6}$ and $2.324 \\times 10^{-4}$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "\n",
    "**Comment on the estimated standard errors obtained using the `glm()` function and using your bootstrap function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard errors obtained by the bootstrap appear to be a quite close to those obtained using the statistical formulas underlying the `glm()` function. This suggests that the data satisfies the underlying assumptions of a logistic regression model: the responses $Y_i$ are independent random variables coming from Bernoulli distributions with probabilities $P_i$, and the log-odds corresponding to $P_i$ is a linear combination of the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 3\n",
    "\n",
    "**In Sections 5.3.2 and 5.3.3, we saw that the `cv.glm()` function can be used in order to compute the LOOCV test error estimate. Alternatively, one could compute those quantities using just the `glm()` and `predict.glm()` functions, and a for loop. You will now take this approach in order to compute the LOOCV error for a simple logistic regression model on the `Weekly` data set. Recall that in the context of classification problems, the LOOCV error is given by the following formula.**\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{CV}_{(n)} = \\frac{1}{n} \\sum_{i = 1}^n I(y_i \\neq \\hat{y}_i)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th><th scope=col>Direction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1990     </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>-0.229   </td><td>-3.484   </td><td>0.1549760</td><td>-0.270   </td><td>Down     </td></tr>\n",
       "\t<tr><td>1990     </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>-0.229   </td><td>0.1485740</td><td>-2.576   </td><td>Down     </td></tr>\n",
       "\t<tr><td>1990     </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>0.1598375</td><td> 3.514   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>0.1616300</td><td> 0.712   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 0.712   </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td>0.1537280</td><td> 1.178   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 1.178   </td><td> 0.712   </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td>0.1544440</td><td>-1.372   </td><td>Down     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction\\\\\n",
       "\\hline\n",
       "\t 1990      &  0.816    &  1.572    & -3.936    & -0.229    & -3.484    & 0.1549760 & -0.270    & Down     \\\\\n",
       "\t 1990      & -0.270    &  0.816    &  1.572    & -3.936    & -0.229    & 0.1485740 & -2.576    & Down     \\\\\n",
       "\t 1990      & -2.576    & -0.270    &  0.816    &  1.572    & -3.936    & 0.1598375 &  3.514    & Up       \\\\\n",
       "\t 1990      &  3.514    & -2.576    & -0.270    &  0.816    &  1.572    & 0.1616300 &  0.712    & Up       \\\\\n",
       "\t 1990      &  0.712    &  3.514    & -2.576    & -0.270    &  0.816    & 0.1537280 &  1.178    & Up       \\\\\n",
       "\t 1990      &  1.178    &  0.712    &  3.514    & -2.576    & -0.270    & 0.1544440 & -1.372    & Down     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Year | Lag1 | Lag2 | Lag3 | Lag4 | Lag5 | Volume | Today | Direction |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1990      |  0.816    |  1.572    | -3.936    | -0.229    | -3.484    | 0.1549760 | -0.270    | Down      |\n",
       "| 1990      | -0.270    |  0.816    |  1.572    | -3.936    | -0.229    | 0.1485740 | -2.576    | Down      |\n",
       "| 1990      | -2.576    | -0.270    |  0.816    |  1.572    | -3.936    | 0.1598375 |  3.514    | Up        |\n",
       "| 1990      |  3.514    | -2.576    | -0.270    |  0.816    |  1.572    | 0.1616300 |  0.712    | Up        |\n",
       "| 1990      |  0.712    |  3.514    | -2.576    | -0.270    |  0.816    | 0.1537280 |  1.178    | Up        |\n",
       "| 1990      |  1.178    |  0.712    |  3.514    | -2.576    | -0.270    | 0.1544440 | -1.372    | Down      |\n",
       "\n"
      ],
      "text/plain": [
       "  Year Lag1   Lag2   Lag3   Lag4   Lag5   Volume    Today  Direction\n",
       "1 1990  0.816  1.572 -3.936 -0.229 -3.484 0.1549760 -0.270 Down     \n",
       "2 1990 -0.270  0.816  1.572 -3.936 -0.229 0.1485740 -2.576 Down     \n",
       "3 1990 -2.576 -0.270  0.816  1.572 -3.936 0.1598375  3.514 Up       \n",
       "4 1990  3.514 -2.576 -0.270  0.816  1.572 0.1616300  0.712 Up       \n",
       "5 1990  0.712  3.514 -2.576 -0.270  0.816 0.1537280  1.178 Up       \n",
       "6 1990  1.178  0.712  3.514 -2.576 -0.270 0.1544440 -1.372 Down     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "**Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag1 + Lag2, family = \"binomial\", data = Weekly)\n",
       "\n",
       "Deviance Residuals: \n",
       "   Min      1Q  Median      3Q     Max  \n",
       "-1.623  -1.261   1.001   1.083   1.506  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.22122    0.06147   3.599 0.000319 ***\n",
       "Lag1        -0.03872    0.02622  -1.477 0.139672    \n",
       "Lag2         0.06025    0.02655   2.270 0.023232 *  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1496.2  on 1088  degrees of freedom\n",
       "Residual deviance: 1488.2  on 1086  degrees of freedom\n",
       "AIC: 1494.2\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(Direction ~ Lag1 + Lag2, data = Weekly, family = \"binomial\")\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "**Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2` *using all but the first observation*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag1 + Lag2, family = \"binomial\", data = Weekly, \n",
       "    subset = c(-1))\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.6258  -1.2617   0.9999   1.0819   1.5071  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.22324    0.06150   3.630 0.000283 ***\n",
       "Lag1        -0.03843    0.02622  -1.466 0.142683    \n",
       "Lag2         0.06085    0.02656   2.291 0.021971 *  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1494.6  on 1087  degrees of freedom\n",
       "Residual deviance: 1486.5  on 1085  degrees of freedom\n",
       "AIC: 1492.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit.loo = glm(Direction ~ Lag1 + Lag2, data = Weekly, family = \"binomial\", subset = c(-1))\n",
    "summary(glm.fit.loo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "**Use the model from Part 2 to predict the direction of the first observation. You can do this by predicting that the first observation will go up if $P(\\text{Direction} = \\text{\"Up\"} | \\text{Lag1, Lag2}) > 0.5$. Was this observation correctly classified?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 0.287534049475059"
      ],
      "text/latex": [
       "\\textbf{1:} 0.287534049475059"
      ],
      "text/markdown": [
       "**1:** 0.287534049475059"
      ],
      "text/plain": [
       "       1 \n",
       "0.287534 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(glm.fit.loo, Weekly[1, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th><th scope=col>Direction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1990    </td><td>0.816   </td><td>1.572   </td><td>-3.936  </td><td>-0.229  </td><td>-3.484  </td><td>0.154976</td><td>-0.27   </td><td>Down    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction\\\\\n",
       "\\hline\n",
       "\t 1990     & 0.816    & 1.572    & -3.936   & -0.229   & -3.484   & 0.154976 & -0.27    & Down    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Year | Lag1 | Lag2 | Lag3 | Lag4 | Lag5 | Volume | Today | Direction |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1990     | 0.816    | 1.572    | -3.936   | -0.229   | -3.484   | 0.154976 | -0.27    | Down     |\n",
       "\n"
      ],
      "text/plain": [
       "  Year Lag1  Lag2  Lag3   Lag4   Lag5   Volume   Today Direction\n",
       "1 1990 0.816 1.572 -3.936 -0.229 -3.484 0.154976 -0.27 Down     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Weekly[1, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the model from Part 2, we predict that the first observation will go down, since the predicted posterior probability from the model is 0.287. This observation was correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "**Write a for loop from $i = 1$ to $i = n$, where $n$ is the number of observations in the data set, that performs each of the following steps:**\n",
    "\n",
    "1. **Fit a logistic regression model using all but the $i$th observation to predict `Direction` using `Lag1` and `Lag2`.**\n",
    "2. **Compute the posterior probability of the market moving up for the $i$th observation.**\n",
    "3. **Use the posterior probability for the $i$th observation in order to predict whether or not the market moves up.**\n",
    "4. **Determine whether or not an error was made in predicting the direction for the $i$th observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = dim(Weekly)[1]\n",
    "errors = rep(0, n)\n",
    "for (i in 1:n){\n",
    "    glm.fit.loo = glm(Direction ~ Lag1 + Lag2, data = Weekly, family = \"binomial\", subset = c(-i))\n",
    "    pred = \"Down\"\n",
    "    if (predict(glm.fit.loo, Weekly[i, ], type = \"response\") > 0.5){\n",
    "        pred = \"Up\"\n",
    "    }\n",
    "    if (pred != Weekly[i, \"Direction\"]){\n",
    "        errors[i] = 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "**Take the average of the $n$ numbers obtained in Step 4 of Part 4 in order to obtain the LOOCV estimate for the test error. Comment on the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.449954086317723"
      ],
      "text/latex": [
       "0.449954086317723"
      ],
      "text/markdown": [
       "0.449954086317723"
      ],
      "text/plain": [
       "[1] 0.4499541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.44995408631772"
      ],
      "text/latex": [
       "0.44995408631772"
      ],
      "text/markdown": [
       "0.44995408631772"
      ],
      "text/plain": [
       "[1] 0.4499541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(Direction ~ Lag1 + Lag2, data = Weekly, family = \"binomial\")\n",
    "cost = function(r, pi) mean(abs(r-pi)> 0.5)\n",
    "cv.err = cv.glm(Weekly, glm.fit, cost = cost)\n",
    "cv.err$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.444444444444444"
      ],
      "text/latex": [
       "0.444444444444444"
      ],
      "text/markdown": [
       "0.444444444444444"
      ],
      "text/plain": [
       "[1] 0.4444444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(Weekly[\"Direction\"] != \"Up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV estimate for the test error is approximately 0.45, which matches the value we get if we use `cv.glm()` to compute the error. This tells us that the logistic regression model using `Lag1` and `Lag2` to predict `Direction` by using a probability threshold of 0.5 performed a bit better than randomly guessing. However, it is important to note that we get essentially the same error rate with a naive strategy of predicting that the market will go up every week. \n",
    "\n",
    "Note that if we wish to use `cv.glm()` to compute the LOOCV test error, by default it computes the errors for the posterior probabilities, since on its own logistic regression is ***not*** a classification method. Performing classification using logistic regression like we have done in this chapter involves choosing a probability threshold for assigning class predictions, based on the posterior probabilities predicted by the logistic regresion model. In order to have `cv.glm()` compute the LOOCV test error for binary classification with a classification threshold of 0.5, as we have done manually with a for loop in Part 4, we need to pass an appropriate cost function to the `cost` argument. Further details can be found in the documentation associated with `?cv.glm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 4\n",
    "\n",
    "**We will now perform cross-validation on a simulated data set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "**Generate a simulated data set as follows:**\n",
    "\n",
    "```\n",
    "> set.seed(1)\n",
    "> x = rnorm(100)\n",
    "> y = x - 2*x^2 + rnorm(100)\n",
    "```\n",
    "\n",
    "**In this data set, what is $n$ and what is $p$? Write out the model used to generate the data in equation form.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "x = rnorm(100)\n",
    "y = x - 2*x^2 + rnorm(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set, $n = 100$ and $p = 1$. In other words, there is one predictor and 100 observations. In equation form, the model used to generate the data is $Y = x - 2X^2 + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "**Create a scatterplot of $X$ against $Y$. Comment on what you find.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAVFBMVEUAAAAXFxcqKio8PDxN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\nAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(x, y, xlim = range(-3:3), ylim = range(-15:4))\n",
    "par(new = TRUE)\n",
    "curve(x - 2*x^2, from = -3, to = 3, xlim = range(-3:3), ylim = range(-15:4), xlab = \"\", ylab = \"\", col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is some noise, especially around the vertex of parabola for the model underlying the data, we can see that for the most part the scatterplot is fairly parabolic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "**Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares:**\n",
    "\n",
    "1. $Y = \\beta_0 + \\beta_1X + \\epsilon$\n",
    "2. $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\epsilon$\n",
    "3. $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon$\n",
    "4. $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\beta_4X^4 + \\epsilon$\n",
    "\n",
    "**Note that you may find it helpful to use the `data.frame()` function to create a single dataset containing both $X$ and $Y$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy.data = data.frame(\"pred\" = x, \"resp\" = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "7.28816160667281"
      ],
      "text/latex": [
       "7.28816160667281"
      ],
      "text/markdown": [
       "7.28816160667281"
      ],
      "text/plain": [
       "[1] 7.288162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deg1.fit = glm(resp ~ pred, data = xy.data)\n",
    "deg1.err = cv.glm(xy.data, deg1.fit)\n",
    "deg1.err$delta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV error for the linear model $Y = \\beta_0 + \\beta_1X + \\epsilon$ is 7.288."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.937423637615552"
      ],
      "text/latex": [
       "0.937423637615552"
      ],
      "text/markdown": [
       "0.937423637615552"
      ],
      "text/plain": [
       "[1] 0.9374236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deg2.fit = glm(resp ~ poly(pred, 2), data = xy.data)\n",
    "deg2.err = cv.glm(xy.data, deg2.fit)\n",
    "deg2.err$delta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV error for the quadratic model $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\epsilon$ is 0.937."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.956621830108939"
      ],
      "text/latex": [
       "0.956621830108939"
      ],
      "text/markdown": [
       "0.956621830108939"
      ],
      "text/plain": [
       "[1] 0.9566218"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deg3.fit = glm(resp ~ poly(pred, 3), data = xy.data)\n",
    "deg3.err = cv.glm(xy.data, deg3.fit)\n",
    "deg3.err$delta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV error for the cubic model $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon$ is 0.957."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.953904892744804"
      ],
      "text/latex": [
       "0.953904892744804"
      ],
      "text/markdown": [
       "0.953904892744804"
      ],
      "text/plain": [
       "[1] 0.9539049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deg4.fit = glm(resp ~ poly(pred, 4), data = xy.data)\n",
    "deg4.err = cv.glm(xy.data, deg4.fit)\n",
    "deg4.err$delta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV error for the quartic model $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\beta_4X^4 + \\epsilon$ is 0.954."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "**Repeat Part 3 using another random seed, and report your results. Are your results the same as what you got in Part 3? Why or why not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "7.28816160667281"
      ],
      "text/latex": [
       "7.28816160667281"
      ],
      "text/markdown": [
       "7.28816160667281"
      ],
      "text/plain": [
       "[1] 7.288162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deg1.fit = glm(resp ~ pred, data = xy.data)\n",
    "deg1.err = cv.glm(xy.data, deg1.fit)\n",
    "deg1.err$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.937423637615552"
      ],
      "text/latex": [
       "0.937423637615552"
      ],
      "text/markdown": [
       "0.937423637615552"
      ],
      "text/plain": [
       "[1] 0.9374236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deg2.fit = glm(resp ~ poly(pred, 2), data = xy.data)\n",
    "deg2.err = cv.glm(xy.data, deg2.fit)\n",
    "deg2.err$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.95662183010894"
      ],
      "text/latex": [
       "0.95662183010894"
      ],
      "text/markdown": [
       "0.95662183010894"
      ],
      "text/plain": [
       "[1] 0.9566218"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deg3.fit = glm(resp ~ poly(pred, 3), data = xy.data)\n",
    "deg3.err = cv.glm(xy.data, deg3.fit)\n",
    "deg3.err$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.953904892744804"
      ],
      "text/latex": [
       "0.953904892744804"
      ],
      "text/markdown": [
       "0.953904892744804"
      ],
      "text/plain": [
       "[1] 0.9539049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deg4.fit = glm(resp ~ poly(pred, 4), data = xy.data)\n",
    "deg4.err = cv.glm(xy.data, deg4.fit)\n",
    "deg4.err$delta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV errors for each model are the same as those computed in Part 3, even with a different seed. This makes sense since LOOCV does not involve any randomness. It always involves fitting a model $\\mathcal{M}_i$ using all of the observations except for observation $X_i$, computing the error between the predicted value $\\hat{Y}_i$ obtained from the model $\\mathcal{M}_i$ and the actual value $Y_i$, and then taking the average of the errors over all $n$ models for the $n$ observations in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "**Which of the models in Part 3 had the smallest LOOCV error? Is this what you expected? Explain your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quadratic model in Part 3 had the smallest LOOCV error, though the cubic and quartic models also had close LOOCV error values, especially compared to the much larger LOOCV error value for the linear model. This is what I expected, since the true model used to produce the simulated data was a quadratic one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6\n",
    "**Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in Part 3 using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I used the `poly()` function to produce orthogonal polynomials for each of the higher-order polynomial fits, as orthogonal polynomials allows for more clear evaluation of the statistical significance of the coefficient estimates for the higher order terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>-1.625427   </td><td>0.2619366   </td><td>-6.205420   </td><td>1.309300e-08</td></tr>\n",
       "\t<tr><th scope=row>pred</th><td> 0.692497   </td><td>0.2909418   </td><td> 2.380191   </td><td>1.923846e-02</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & -1.625427    & 0.2619366    & -6.205420    & 1.309300e-08\\\\\n",
       "\tpred &  0.692497    & 0.2909418    &  2.380191    & 1.923846e-02\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | -1.625427    | 0.2619366    | -6.205420    | 1.309300e-08 |\n",
       "| pred |  0.692497    | 0.2909418    |  2.380191    | 1.923846e-02 |\n",
       "\n"
      ],
      "text/plain": [
       "            Estimate  Std. Error t value   Pr(>|t|)    \n",
       "(Intercept) -1.625427 0.2619366  -6.205420 1.309300e-08\n",
       "pred         0.692497 0.2909418   2.380191 1.923846e-02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(deg1.fit)$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the linear model, the coefficient estimate is statistically significant at the 5% level. This result agrees with the high LOOCV error obtained in Part 3, which suggested that a purely linear fit was not appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td> -1.550023  </td><td>0.09580323  </td><td>-16.179231  </td><td>2.656229e-29</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 2)1</th><td>  6.188826  </td><td>0.95803228  </td><td>  6.459934  </td><td>4.184810e-09</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 2)2</th><td>-23.948305  </td><td>0.95803228  </td><td>-24.997388  </td><td>4.584330e-44</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) &  -1.550023   & 0.09580323   & -16.179231   & 2.656229e-29\\\\\n",
       "\tpoly(pred, 2)1 &   6.188826   & 0.95803228   &   6.459934   & 4.184810e-09\\\\\n",
       "\tpoly(pred, 2)2 & -23.948305   & 0.95803228   & -24.997388   & 4.584330e-44\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) |  -1.550023   | 0.09580323   | -16.179231   | 2.656229e-29 |\n",
       "| poly(pred, 2)1 |   6.188826   | 0.95803228   |   6.459934   | 4.184810e-09 |\n",
       "| poly(pred, 2)2 | -23.948305   | 0.95803228   | -24.997388   | 4.584330e-44 |\n",
       "\n"
      ],
      "text/plain": [
       "               Estimate   Std. Error t value    Pr(>|t|)    \n",
       "(Intercept)     -1.550023 0.09580323 -16.179231 2.656229e-29\n",
       "poly(pred, 2)1   6.188826 0.95803228   6.459934 4.184810e-09\n",
       "poly(pred, 2)2 -23.948305 0.95803228 -24.997388 4.584330e-44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(deg2.fit)$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the quadratic model, both coefficient estimates are highly statistically significant. In particular, the p-values for the coefficients of both the quadratic and linear terms are essentially zero. This agrees with the large drop in LOOCV error going from the linear fit to the quadratic fit, which suggested that a quadratic fit was more appropriate than a purely linear one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td> -1.5500226 </td><td>0.09626318  </td><td>-16.101926  </td><td>4.995066e-29</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 3)1</th><td>  6.1888256 </td><td>0.96263178  </td><td>  6.429068  </td><td>4.971565e-09</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 3)2</th><td>-23.9483049 </td><td>0.96263178  </td><td>-24.877950  </td><td>1.216703e-43</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 3)3</th><td>  0.2641057 </td><td>0.96263178  </td><td>  0.274358  </td><td>7.843990e-01</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) &  -1.5500226  & 0.09626318   & -16.101926   & 4.995066e-29\\\\\n",
       "\tpoly(pred, 3)1 &   6.1888256  & 0.96263178   &   6.429068   & 4.971565e-09\\\\\n",
       "\tpoly(pred, 3)2 & -23.9483049  & 0.96263178   & -24.877950   & 1.216703e-43\\\\\n",
       "\tpoly(pred, 3)3 &   0.2641057  & 0.96263178   &   0.274358   & 7.843990e-01\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) |  -1.5500226  | 0.09626318   | -16.101926   | 4.995066e-29 |\n",
       "| poly(pred, 3)1 |   6.1888256  | 0.96263178   |   6.429068   | 4.971565e-09 |\n",
       "| poly(pred, 3)2 | -23.9483049  | 0.96263178   | -24.877950   | 1.216703e-43 |\n",
       "| poly(pred, 3)3 |   0.2641057  | 0.96263178   |   0.274358   | 7.843990e-01 |\n",
       "\n"
      ],
      "text/plain": [
       "               Estimate    Std. Error t value    Pr(>|t|)    \n",
       "(Intercept)     -1.5500226 0.09626318 -16.101926 4.995066e-29\n",
       "poly(pred, 3)1   6.1888256 0.96263178   6.429068 4.971565e-09\n",
       "poly(pred, 3)2 -23.9483049 0.96263178 -24.877950 1.216703e-43\n",
       "poly(pred, 3)3   0.2641057 0.96263178   0.274358 7.843990e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(deg3.fit)$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cubic model, the linear and quadratic terms are both highly statistically significant, but the cubic term is not. In particular, the p-value for the cubic term is 0.784, which is quite high. This agrees with the fact that while the LOOCV error for the cubic fit is still much lower than the LOOCV error for the linear fit, it is slightly higher than this LOOCV error for the quadratic fit, which suggests that a quadratic fit is likely to be more appropriate than a cubic fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td> -1.5500226 </td><td>0.09590514  </td><td>-16.1620379 </td><td>5.169227e-29</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 4)1</th><td>  6.1888256 </td><td>0.95905143  </td><td>  6.4530695 </td><td>4.590732e-09</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 4)2</th><td>-23.9483049 </td><td>0.95905143  </td><td>-24.9708243 </td><td>1.593826e-43</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 4)3</th><td>  0.2641057 </td><td>0.95905143  </td><td>  0.2753822 </td><td>7.836207e-01</td></tr>\n",
       "\t<tr><th scope=row>poly(pred, 4)4</th><td>  1.2570950 </td><td>0.95905143  </td><td>  1.3107691 </td><td>1.930956e-01</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) &  -1.5500226  & 0.09590514   & -16.1620379  & 5.169227e-29\\\\\n",
       "\tpoly(pred, 4)1 &   6.1888256  & 0.95905143   &   6.4530695  & 4.590732e-09\\\\\n",
       "\tpoly(pred, 4)2 & -23.9483049  & 0.95905143   & -24.9708243  & 1.593826e-43\\\\\n",
       "\tpoly(pred, 4)3 &   0.2641057  & 0.95905143   &   0.2753822  & 7.836207e-01\\\\\n",
       "\tpoly(pred, 4)4 &   1.2570950  & 0.95905143   &   1.3107691  & 1.930956e-01\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) |  -1.5500226  | 0.09590514   | -16.1620379  | 5.169227e-29 |\n",
       "| poly(pred, 4)1 |   6.1888256  | 0.95905143   |   6.4530695  | 4.590732e-09 |\n",
       "| poly(pred, 4)2 | -23.9483049  | 0.95905143   | -24.9708243  | 1.593826e-43 |\n",
       "| poly(pred, 4)3 |   0.2641057  | 0.95905143   |   0.2753822  | 7.836207e-01 |\n",
       "| poly(pred, 4)4 |   1.2570950  | 0.95905143   |   1.3107691  | 1.930956e-01 |\n",
       "\n"
      ],
      "text/plain": [
       "               Estimate    Std. Error t value     Pr(>|t|)    \n",
       "(Intercept)     -1.5500226 0.09590514 -16.1620379 5.169227e-29\n",
       "poly(pred, 4)1   6.1888256 0.95905143   6.4530695 4.590732e-09\n",
       "poly(pred, 4)2 -23.9483049 0.95905143 -24.9708243 1.593826e-43\n",
       "poly(pred, 4)3   0.2641057 0.95905143   0.2753822 7.836207e-01\n",
       "poly(pred, 4)4   1.2570950 0.95905143   1.3107691 1.930956e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(deg4.fit)$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the quartic model, the linear and quadratic terms are both highly statistically significant, but the cubic and quartic terms are not. In particular, the p-values for the cubic and quartic terms are 0.784 and 0.193, respectively, which are quite high. This agrees with the fact that while the LOOCV error for the quartic fit is still much lower than the LOOCV error for the linear fit, it is slightly higher than this LOOCV error for the quadratic fit, which suggests that a quadratic fit is likely to be more appropriate than a quartic fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Exercise 5\n",
    "**Weill we now consider the `Boston` housing data set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have consistency with my results for when I do these exercises in Python, I'll use the corrected Boston housing data set instead of the one that is part of the `MASS` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>CMEDV</th><th scope=col>CRIM</th><th scope=col>ZN</th><th scope=col>INDUS</th><th scope=col>CHAS</th><th scope=col>NOX</th><th scope=col>RM</th><th scope=col>AGE</th><th scope=col>DIS</th><th scope=col>RAD</th><th scope=col>TAX</th><th scope=col>PTRATIO</th><th scope=col>B</th><th scope=col>LSTAT</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>24.0   </td><td>0.00632</td><td>18     </td><td>2.31   </td><td>0      </td><td>0.538  </td><td>6.575  </td><td>65.2   </td><td>4.0900 </td><td>1      </td><td>296    </td><td>15.3   </td><td>396.90 </td><td>4.98   </td></tr>\n",
       "\t<tr><td>21.6   </td><td>0.02731</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>6.421  </td><td>78.9   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>396.90 </td><td>9.14   </td></tr>\n",
       "\t<tr><td>34.7   </td><td>0.02729</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>7.185  </td><td>61.1   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>392.83 </td><td>4.03   </td></tr>\n",
       "\t<tr><td>33.4   </td><td>0.03237</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.998  </td><td>45.8   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.63 </td><td>2.94   </td></tr>\n",
       "\t<tr><td>36.2   </td><td>0.06905</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>7.147  </td><td>54.2   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>396.90 </td><td>5.33   </td></tr>\n",
       "\t<tr><td>28.7   </td><td>0.02985</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.430  </td><td>58.7   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.12 </td><td>5.21   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllll}\n",
       " CMEDV & CRIM & ZN & INDUS & CHAS & NOX & RM & AGE & DIS & RAD & TAX & PTRATIO & B & LSTAT\\\\\n",
       "\\hline\n",
       "\t 24.0    & 0.00632 & 18      & 2.31    & 0       & 0.538   & 6.575   & 65.2    & 4.0900  & 1       & 296     & 15.3    & 396.90  & 4.98   \\\\\n",
       "\t 21.6    & 0.02731 &  0      & 7.07    & 0       & 0.469   & 6.421   & 78.9    & 4.9671  & 2       & 242     & 17.8    & 396.90  & 9.14   \\\\\n",
       "\t 34.7    & 0.02729 &  0      & 7.07    & 0       & 0.469   & 7.185   & 61.1    & 4.9671  & 2       & 242     & 17.8    & 392.83  & 4.03   \\\\\n",
       "\t 33.4    & 0.03237 &  0      & 2.18    & 0       & 0.458   & 6.998   & 45.8    & 6.0622  & 3       & 222     & 18.7    & 394.63  & 2.94   \\\\\n",
       "\t 36.2    & 0.06905 &  0      & 2.18    & 0       & 0.458   & 7.147   & 54.2    & 6.0622  & 3       & 222     & 18.7    & 396.90  & 5.33   \\\\\n",
       "\t 28.7    & 0.02985 &  0      & 2.18    & 0       & 0.458   & 6.430   & 58.7    & 6.0622  & 3       & 222     & 18.7    & 394.12  & 5.21   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| CMEDV | CRIM | ZN | INDUS | CHAS | NOX | RM | AGE | DIS | RAD | TAX | PTRATIO | B | LSTAT |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 24.0    | 0.00632 | 18      | 2.31    | 0       | 0.538   | 6.575   | 65.2    | 4.0900  | 1       | 296     | 15.3    | 396.90  | 4.98    |\n",
       "| 21.6    | 0.02731 |  0      | 7.07    | 0       | 0.469   | 6.421   | 78.9    | 4.9671  | 2       | 242     | 17.8    | 396.90  | 9.14    |\n",
       "| 34.7    | 0.02729 |  0      | 7.07    | 0       | 0.469   | 7.185   | 61.1    | 4.9671  | 2       | 242     | 17.8    | 392.83  | 4.03    |\n",
       "| 33.4    | 0.03237 |  0      | 2.18    | 0       | 0.458   | 6.998   | 45.8    | 6.0622  | 3       | 222     | 18.7    | 394.63  | 2.94    |\n",
       "| 36.2    | 0.06905 |  0      | 2.18    | 0       | 0.458   | 7.147   | 54.2    | 6.0622  | 3       | 222     | 18.7    | 396.90  | 5.33    |\n",
       "| 28.7    | 0.02985 |  0      | 2.18    | 0       | 0.458   | 6.430   | 58.7    | 6.0622  | 3       | 222     | 18.7    | 394.12  | 5.21    |\n",
       "\n"
      ],
      "text/plain": [
       "  CMEDV CRIM    ZN INDUS CHAS NOX   RM    AGE  DIS    RAD TAX PTRATIO B     \n",
       "1 24.0  0.00632 18 2.31  0    0.538 6.575 65.2 4.0900 1   296 15.3    396.90\n",
       "2 21.6  0.02731  0 7.07  0    0.469 6.421 78.9 4.9671 2   242 17.8    396.90\n",
       "3 34.7  0.02729  0 7.07  0    0.469 7.185 61.1 4.9671 2   242 17.8    392.83\n",
       "4 33.4  0.03237  0 2.18  0    0.458 6.998 45.8 6.0622 3   222 18.7    394.63\n",
       "5 36.2  0.06905  0 2.18  0    0.458 7.147 54.2 6.0622 3   222 18.7    396.90\n",
       "6 28.7  0.02985  0 2.18  0    0.458 6.430 58.7 6.0622 3   222 18.7    394.12\n",
       "  LSTAT\n",
       "1 4.98 \n",
       "2 9.14 \n",
       "3 4.03 \n",
       "4 2.94 \n",
       "5 5.33 \n",
       "6 5.21 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boston = read.csv(\"boston_corrected.csv\", header = TRUE)\n",
    "boston = boston[, 7:20]\n",
    "head(boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "**Based on this data set, provide an estimate for the population mean of `CMEDV`. Call this estimate $\\hat{\\mu}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "22.5288537549407"
      ],
      "text/latex": [
       "22.5288537549407"
      ],
      "text/markdown": [
       "22.5288537549407"
      ],
      "text/plain": [
       "[1] 22.52885"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(boston$CMEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated population mean of `CMEDV` is $\\hat{\\mu} = 22.529$. In other words, the average median home value for this sample is \\$22,529."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "**Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this result.**\n",
    "\n",
    "***Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.408197507828407"
      ],
      "text/latex": [
       "0.408197507828407"
      ],
      "text/markdown": [
       "0.408197507828407"
      ],
      "text/plain": [
       "[1] 0.4081975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample.sd = sd(boston$CMEDV)\n",
    "sample.sem = sample.sd / sqrt(dim(boston)[1])\n",
    "sample.sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [usual formula for estimating the standard error](https://en.wikipedia.org/wiki/Standard_error), we get a value of 0.408 as our estimate for the standard error of $\\hat{\\mu}$. Since `CMEDV` was measured in units of 1,000 USD, this estimate of the standard error translates to \\$408. We will further interpret what this estimate of standard error means in Part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "**Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. How does this compare to your answer from Part 2?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.fn = function(data, index){\n",
    "    return(mean(data[index, \"CMEDV\"]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = boston, statistic = boot.fn, R = 10000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original      bias    std. error\n",
       "t1* 22.52885 0.001582826   0.4060708"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(boston, boot.fn, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bootstrap, we have an estimate of 0.406 for the standard error of $\\hat{\\mu}$. This is very close to the estimate obtained in Part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4\n",
    "**Based on your bootstrap estimate from Part 3, provide a 95% confidence interval for the mean of `CMEDV`. Compare it to the results obtained using `t.test(Boston$CMEDV)`.**\n",
    "\n",
    "***Hint: You can approximate a 95% confidence interval using the formula $[ \\hat{\\mu} - 2\\text{SE}(\\hat{\\mu}), \\hat{\\mu} + 2\\text{SE}(\\hat{\\mu}) ]$.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  boston$CMEDV\n",
       "t = 55.191, df = 505, p-value < 2.2e-16\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 21.72688 23.33083\n",
       "sample estimates:\n",
       "mean of x \n",
       " 22.52885 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(boston$CMEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our bootstrap estimate from Part 3, a 95% confidence interval for the mean of `CMEDV` is approximately $[22.529 - 2 \\times 0.406, \\, 22.529 + 2 \\times 0.406]$, or $[21.717, \\, 23.341]$. This is slightly wider than the confidence interval computed using `t.test()`, since we rounded our critical $t$-value up to 2, when for our data set with 506 observations the actual critical $t$-value is approximately 1.960. The meaning of a 95% confidence interval is that if we repeatedly sampled from the population and used the sample means and estimated standard errors to compute many confidence intervals, approximately 95% of those confidence intervals will contain the actual population mean. In other words, there is a 95% chance that this confidence interval contains the actual population mean of `CMEDV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5\n",
    "**Based on this dataset, provide an estimate, $\\hat{\\mu}_{\\text{med}}$, for the median value of `CMEDV` in the population.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "21.2"
      ],
      "text/latex": [
       "21.2"
      ],
      "text/markdown": [
       "21.2"
      ],
      "text/plain": [
       "[1] 21.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "median(boston$CMEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated population median of `CMEDV` is $\\hat{\\mu}_{\\text{med}} = 21.2$. In other words, the median of median home values for this sample is \\$21,200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6\n",
    "**We would now like to estimate the standard error of $\\hat{\\mu}_{\\text{med}}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.fn = function(data, index){\n",
    "    return(median(data[index, \"CMEDV\"]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = boston, statistic = boot.fn, R = 10000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original   bias    std. error\n",
       "t1*     21.2 -0.01289   0.3760705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(boston, boot.fn, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bootstrap, we have an estimate of 0.376 for the standard error of $\\hat{\\mu}_{\\text{med}}$. Based on this bootstrap estimate, a 95% confidence interval for the median of `CMEDV` is approximately $[21.2 - 2 \\times 0.376, \\, 21.2 + 2 \\times 0.376]$, or $[20.448, \\, 21.952]$. There is a 95% chance that this confidence interval contains the actual population median of `CMEDV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7\n",
    "**Based on this data set, provide an estimate for the tenth percentile of `CMEDV` in Boston suburbs. Call this quantity $\\hat{\\mu}_{0.1}$. To compute this estimate, you can use the `quantile()` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>10%:</strong> 12.9"
      ],
      "text/latex": [
       "\\textbf{10\\textbackslash{}\\%:} 12.9"
      ],
      "text/markdown": [
       "**10%:** 12.9"
      ],
      "text/plain": [
       " 10% \n",
       "12.9 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantile(boston$CMEDV, c(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated population tenth percentile of `CMEDV` is $\\hat{\\mu}_{0.1} = 12.9$. In other words, the tenth percentile of median home values for this sample is \\$12,900, or only 10% of observations in this sample have a `CMEDV` value of 12.9 or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8\n",
    "**Use the bootstrap to estimate the standard error of $\\hat{\\mu}_{0.1}$. Comment on your findings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.fn = function(data, index){\n",
    "    return(quantile(data[index, \"CMEDV\"], 0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = boston, statistic = boot.fn, R = 10000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original   bias    std. error\n",
       "t1*     12.9 -0.07158   0.4876654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(boston, boot.fn, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bootstrap, we have an estimate of 0.488 for the standard error of $\\hat{\\mu}_{0.1}$. Based on this bootstrap estimate, a 95% confidence interval for the tenth percentile of `CMEDV` is approximately $[12.9 - 2 \\times 0.488, \\, 12.9 + 2 \\times 0.488]$, or $[11.924, \\, 13.876]$. There is a 95% chance that this confidence interval contains the actual population tenth percentile of `CMEDV`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
